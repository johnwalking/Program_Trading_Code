{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"code2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"RYvAT5jaPfNj"},"source":["Package Installation"]},{"cell_type":"code","metadata":{"id":"lc_R_vbhKSNw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605699235554,"user_tz":-480,"elapsed":85923,"user":{"displayName":"王成中","photoUrl":"","userId":"06411389530591681249"}},"outputId":"08347fce-cd36-4076-8ba8-8956874efd64"},"source":["!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb\n","!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb\n","!dpkg -i libta.deb ta.deb\n","!pip install ta-lib\n","import talib\n","!pip install mpl_finance\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selecting previously unselected package libta-lib0.\n","(Reading database ... 144793 files and directories currently installed.)\n","Preparing to unpack libta.deb ...\n","Unpacking libta-lib0 (0.4.0-oneiric1) ...\n","Selecting previously unselected package ta-lib0-dev.\n","Preparing to unpack ta.deb ...\n","Unpacking ta-lib0-dev (0.4.0-oneiric1) ...\n","Setting up libta-lib0 (0.4.0-oneiric1) ...\n","Setting up ta-lib0-dev (0.4.0-oneiric1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Collecting ta-lib\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/cf/681911aa31e04ba171ab4d523a412f4a746e30d3eacb1738799d181e028b/TA-Lib-0.4.19.tar.gz (267kB)\n","\u001b[K     |████████████████████████████████| 276kB 5.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta-lib) (1.18.5)\n","Building wheels for collected packages: ta-lib\n","  Building wheel for ta-lib (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ta-lib: filename=TA_Lib-0.4.19-cp36-cp36m-linux_x86_64.whl size=1437791 sha256=19223b02b747915cb680cfde95a3e59e161d859381308bf0acf75528261b2848\n","  Stored in directory: /root/.cache/pip/wheels/a3/f6/12/3d1ccd06caadd8fa47e016991dd0d27f1163bb260f1854e2ff\n","Successfully built ta-lib\n","Installing collected packages: ta-lib\n","Successfully installed ta-lib-0.4.19\n","Collecting mpl_finance\n","  Downloading https://files.pythonhosted.org/packages/9d/de/8169ea4403d6cb8322e74cc48b6834d1dfbed81931d17f1f26b2140160d8/mpl_finance-0.10.1-py3-none-any.whl\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mpl_finance) (3.2.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mpl_finance) (1.3.1)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mpl_finance) (1.18.5)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mpl_finance) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mpl_finance) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mpl_finance) (2.8.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->mpl_finance) (1.15.0)\n","Installing collected packages: mpl-finance\n","Successfully installed mpl-finance-0.10.1\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vrWPAtaTPgzE"},"source":["Stock Number"]},{"cell_type":"code","metadata":{"id":"Dco_95bUYgd8"},"source":["stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\",\n","            \"2105\", \"2207\", \n","            # \"2227\", \n","            \"2301\", \"2303\", \"2308\", \"2317\", \"2327\",\n","            \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\",\n","            \"2633\", \"2801\", \"2823\", \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\",\n","            \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\",\n","            \"4904\", \"4938\", \"5871\", \"5880\", \"6505\", \"9904\", \"9910\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"41QAdLUtPtFw"},"source":["GPU Environment Setting"]},{"cell_type":"code","metadata":{"id":"gJ7gcC7gPv-C"},"source":["import tensorflow as tf\n","from tensorflow.keras import *\n","gpus = tf.config.list_physical_devices(\"GPU\")\n","if gpus:\n","    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n","    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n","    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n","    # tf.config.experimental.set_virtual_device_configuration(gpu0,\n","    # [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n","    tf.config.set_visible_devices([gpu0],\"GPU\") "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EmFb1ek5P4bj"},"source":["\n","Import Package"]},{"cell_type":"code","metadata":{"id":"FK5IkzcuYgeA"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import talib\n","import pandas_datareader as pdr\n","import mpl_finance as mpf\n","import seaborn as sns\n","import datetime as datetime\n","from sklearn import preprocessing\n","import requests\n","import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Input, Dense\n","from PIL import Image, ImageDraw, ImageFont\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n","import csv\n","import statistics\n","import math\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, SpatialDropout2D, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D,MaxPooling1D\n","from tensorflow.keras.layers import Activation,Dense ,Dropout ,GRU, ConvLSTM2D ,LSTM ,Bidirectional,TimeDistributed,Flatten, Conv1D, MaxPooling1D,BatchNormalization\n","from tensorflow.keras.optimizers import SGD, RMSprop\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import layers \n","from tensorflow.keras.layers import LayerNormalization\n","from tensorflow.python.keras.layers import Input, Embedding, Dot, Reshape, Dense\n","from tensorflow.python.keras.models import Model\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.optimizers import Adamax, Adam\n","from tensorflow.keras.layers import Input,Embedding,LSTM,Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rLAcNEFio8yw"},"source":["Exponential Smoothing + One-Hot Encoding"]},{"cell_type":"code","metadata":{"id":"p4eR8bmeprms"},"source":["def exponential_smoothing(days, alpha, numdata):\n","  # assign weights\n","  weights = []\n","  i = days \n","  while i>0:\n","    weights.append( math.exp(-alpha*i) )\n","    i-=1\n","  weights = np.array(weights) / sum(weights)\n","  # return data after smoothing\n","  results = []\n","  results += numdata[:days]\n","  for i in range(days, len(numdata)):\n","    results.append((np.dot( np.array(weights), np.array(numdata[i-days:i]))))\n","  return results\n","\n","classes =['0', '1']\n","def to_onelist(text):\n","    onehot = [0] * 2\n","    onehot[ int(classes.index(str(text)) ) ] = 1\n","    label_list = np.array(onehot)\n","    return label_list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2mdOh5OCUPwN"},"source":["Preparation for data collection"]},{"cell_type":"code","metadata":{"id":"UlJF3f7FP7US"},"source":["pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('max_colwidth',100)\n","start = '2005/01/01'\n","end = '2020/09/21'\n","s = start.split('/')\n","e = end.split('/')\n","start = datetime.datetime(int(s[0]), int(s[1]), int(s[2]))\n","end = datetime.datetime(int(e[0]), int(e[1]), int(e[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nPBl2JcRYgeE"},"source":["# for stockno in stockNum:\n","#     # load 進 五大價格 一個量\n","#     df = pdr.DataReader(str(stockno)+'.TW', 'yahoo', start=start, end=end)\n","#     df.index = df.index.format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n","#     # print(df.columns)\n","#     stock_time = str(df.index[0]).split(\" \")[0]\n","#     #load in 融資融券\n","#     url = \"https://api.finmindtrade.com/api/v3/data\"\n","#     parameter = {\n","#         \"dataset\": \"TaiwanStockMarginPurchaseShortSale\",\n","#         \"stock_id\": str(stockno),\n","#         \"date\": stock_time,\n","#     }\n","#     data = requests.get(url, params=parameter)\n","#     data = data.json()\n","#     data = pd.DataFrame(data['data'])\n","#     #if 沒資料 則跳過這張股票\n","#     if data.empty == True:\n","#         print(str(stockno)+\" can't find data !\")\n","#         continue\n","#     ratio = []\n","#     b_total = []\n","#     s_total = []\n","#     for i in range(len(data)):\n","#         b_total.append(data['MarginPurchaseLimit'][i] - data['MarginPurchaseTodayBalance'][i])\n","#         s_total.append(data['ShortSaleLimit'][i] - data['ShortSaleTodayBalance'][i])\n","#         ratio.append(float(data['ShortSaleLimit'][i] - data['ShortSaleTodayBalance'][i])/(data['MarginPurchaseLimit'][i] - data['MarginPurchaseTodayBalance'][i]+1))\n","#     data['b_total'] = b_total\n","#     data['s_total'] = s_total\n","#     data['b_s_ratio'] = ratio\n","#     data = data.set_index('date')\n","#     #合併這兩個表格\n","#     new_df = df.join(data)\n","#     new_df = new_df.drop(['stock_id'], axis=1)\n","#     new_df = new_df.drop(['ShortSaleCashRepayment'], axis=1)\n","#     #處理三大法人投資情況 視情況加入\n","#     url = \"https://api.finmindtrade.com/api/v3/data\"\n","#     parameter = {\n","#         \"dataset\": \"InstitutionalInvestorsBuySell\",\n","#         \"stock_id\": str(stockno),\n","#         \"date\": stock_time,\n","#     }\n","#     data = requests.get(url, params=parameter)\n","#     data = data.json()\n","#     data = pd.DataFrame(data['data'])\n","#     if data.empty == True:\n","#         print(str(stockno)+\" can't find data !\")\n","#         continue\n","#     df = pd.DataFrame()\n","#     z = 0 \n","#     i = 0\n","#     while i < len(data)  :\n","#         a = data['date'][i]\n","#         count = 0\n","#         sell  = 0\n","#         buy = 0 \n","#         if i+6 < len(data)-1:\n","#             for j  in range(i, i+6):\n","#                 if data['date'][j]== a :\n","#                     count += 1\n","#                     sell += data['sell'][j]\n","#                     buy += data['buy'][j]\n","#         else:\n","#             for j in range(i, len(data)):\n","#                 if data['date'][j] == a :\n","#                     count += 1\n","#                     sell += data['sell'][j]\n","#                     buy += data['buy'][j]\n","#         df = df.append({'date': a, 'buy_volume': buy, 'sell_volume':sell, 'bs_ratio':buy/(sell+1)}, ignore_index=True)\n","#         i+=count\n","#     # combine\n","#     new_df = new_df.join(df.set_index('date'))\n","#     new_df = new_df.dropna(axis=0,how='any')\n","#     new_df.reset_index(drop=True, inplace=True)\n","#     new_df = new_df.drop(['Note'], axis=1)\n","#     for columnName in ['Close','High', 'Low','Open']:\n","#         if str(columnName) == 'y_label' : continue\n","#         new_df[str(columnName)] = exponential_smoothing(5, 0.2, list(new_df[str(columnName)]))\n","#     pred_days = 5\n","#     ans = []\n","#     for i in range(len(new_df)-pred_days):\n","#         Pi = new_df['Close'][i+pred_days]\n","#         Pj = new_df['Close'][i]\n","#         if Pi > Pj : y = 1\n","#         else: y = 0\n","#         ans.append(y)\n","#     ans += [0]*pred_days\n","#     new_df['y_label']= ans\n","    \n","#     #store file\n","#     new_df = new_df[5:]\n","#     from google.colab import files\n","#     new_df.to_csv('/content/drive/My Drive/Program_Trading_Code/0050_stock_5_5(for_price)/'+str(stockno)+'.csv')\n","#     # from google.colab import files\n","#     # files.download('/content/drive/My_Drive/Program_Trading_Code/0050_stock_5_5/'+str(stockno)+'.csv')\n","#     print(str(stockno)+\" complete....\")\n","\n","#     def normalization(df):\n","#     #{'date': a, 'buy_volume': buy, 'sell_volume':sell, 'bs_ratio':buy/(sell+1)}\n","#       dic = {}\n","#       for col in df.columns:\n","#           if col == 'Date' or col == 'y_label' or col =='bs_ratio' or col =='b_s_ratio': continue\n","#           else:\n","#               mean = statistics.mean(df[str(col)])\n","#               stdev = statistics.stdev(df[str(col)])\n","#               if stdev == 0: stdev = 1\n","#           dic[str(col)+'_mean'] = mean\n","#           dic[str(col)+'_stdev'] = stdev\n","#       return dic\n","#     record = pd.DataFrame()\n","#     days_before = 30\n","#     for i in range(days_before, len(new_df)):\n","#       record = record.append(normalization(new_df[i-days_before:i]), ignore_index=True )\n","#     record.to_csv('/content/drive/My Drive/Program_Trading_Code/0050_stock_5_5(for_price)/'+str(stockno)+'mean&stdev.csv')\n","#     print(str(stockno)+\" mean & stdev complete....\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2thBicsOpEIv"},"source":["Load in training / validation / testing data"]},{"cell_type":"code","metadata":{"id":"Ydtw16qQpt3j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604196355926,"user_tz":-480,"elapsed":520651,"user":{"displayName":"Haren Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjM7LUGwDdn3CACBmSa5bdxiAwKb6p7ehD49gbxuA=s64","userId":"06735001407493510827"}},"outputId":"0a647f6a-fd30-4392-9979-c82112a45346"},"source":["\n","\n","\n","pd.options.mode.chained_assignment = None \n","\n","train_x = []\n","test_x = []\n","val_x = []\n","val_y = []\n","train_y = []\n","test_y = []\n","\n","for stockno in stockNum:\n","    x = []\n","    if int(stockno) == 2227: continue\n","    df = pd.read_csv('/content/drive/My Drive/Program_Trading_Code/0050_stock_5_5(for_price)/'+str(stockno)+'.csv')\n","    record = pd.read_csv('/content/drive/My Drive/Program_Trading_Code/0050_stock_5_5(for_price)/'+str(stockno)+'mean&stdev.csv')\n","    df.rename(columns={'Unnamed: 0':'Date'}, inplace=True)\n","    df = df.drop(['Date'], axis=1)\n","    df = df.drop(['MarginPurchaseLimit'], axis=1)\n","    df = df.drop(['ShortSaleLimit'], axis=1)\n","    df = df.dropna(axis=0, how='any')\n","    df.reset_index(drop=True, inplace=True)\n","    days_before = 30\n","    for i in range(days_before, len(df)):\n","        tmp = df[i-days_before:i]\n","        for col in df.columns:\n","          if col == 'Date' or col == 'y_label' or col =='bs_ratio' or col =='b_s_ratio': continue\n","          mean = record[str(col)+'_mean'][i-30]\n","          stdev = record[str(col)+'_stdev'][i-30]\n","          def test(s): \n","            return (float(s)-mean)/stdev\n","          tmp[str(col)].map(test)\n","        x.append( np.array(np.array(tmp).tolist()[0: days_before]).reshape(days_before,len(tmp.columns)))\n","    y = list(df['y_label'][days_before:]) \n","    #train:val:test = 8:1:1\n","    tr_va = int(len(x)*8/10)\n","    va_te = int(len(x)*9/10)\n","    # print(\"no: \", tr_va, \"no: \", va_te, \"leng: \", len(y))\n","    train_x = train_x + x[:tr_va]\n","    train_y = train_y + y[:tr_va]\n","    val_x = val_x + x[tr_va: va_te]\n","    val_y = val_y + y[tr_va: va_te]\n","    test_x = test_x + x[va_te:]\n","    test_y = test_y +y[va_te:]\n","    print(str(stockno)+\" loaded....\")\n","    # print(len(train_x), len(val_x), len(test_x))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1101 loaded....\n","1102 loaded....\n","1216 loaded....\n","1301 loaded....\n","1326 loaded....\n","1402 loaded....\n","2002 loaded....\n","2105 loaded....\n","2207 loaded....\n","2301 loaded....\n","2303 loaded....\n","2308 loaded....\n","2317 loaded....\n","2327 loaded....\n","2330 loaded....\n","2352 loaded....\n","2357 loaded....\n","2382 loaded....\n","2395 loaded....\n","2408 loaded....\n","2412 loaded....\n","2454 loaded....\n","2474 loaded....\n","2609 loaded....\n","2610 loaded....\n","2633 loaded....\n","2801 loaded....\n","2823 loaded....\n","2880 loaded....\n","2881 loaded....\n","2882 loaded....\n","2883 loaded....\n","2884 loaded....\n","2885 loaded....\n","2886 loaded....\n","2887 loaded....\n","2888 loaded....\n","2890 loaded....\n","2891 loaded....\n","2892 loaded....\n","2912 loaded....\n","3008 loaded....\n","3045 loaded....\n","3711 loaded....\n","4904 loaded....\n","4938 loaded....\n","5871 loaded....\n","5880 loaded....\n","6505 loaded....\n","9904 loaded....\n","9910 loaded....\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WAfWCZAQgyWi"},"source":["start = '2012/01/01'\n","end = '2020/09/21'\n","s = start.split('/')\n","e = end.split('/')\n","start = datetime.datetime(int(s[0]), int(s[1]), int(s[2]))\n","end = datetime.datetime(int(e[0]), int(e[1]), int(e[2]))\n","# Price_df = pdr.DataReader(str(2330)+'.TW', 'yahoo', start=start, end=end)\n","# Price_df.index = Price_df.index.format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n","# Price_df = Price_df.reset_index()\n","# Price_df = Price_df[-2016:]\n","# print(Price_df.columns)\n","# print(Price_df['index'][1612])\n","# print(Price_df['index'][1814])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MTSbJuRYpypc"},"source":["y = [] \n","for i in range(len(train_y)):\n","    y.append(to_onelist(str(train_y[i])))\n","train_y = y\n","\n","y = [] \n","for i in range(len(test_y)):\n","    y.append(to_onelist(str(test_y[i])))\n","test_y = y\n","\n","y = [] \n","for i in range(len(val_y)):\n","    y.append(to_onelist(str(val_y[i])))\n","val_y = y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWJix2TRx517","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604196355931,"user_tz":-480,"elapsed":520648,"user":{"displayName":"Haren Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjM7LUGwDdn3CACBmSa5bdxiAwKb6p7ehD49gbxuA=s64","userId":"06735001407493510827"}},"outputId":"227610b6-baa2-46ab-db9f-bdf101df3551"},"source":["def count_label_dist(arr):\n","    count_1 = 0 \n","    count_0 = 0 \n","    for i in range(len(arr)):\n","        if list(arr[i])== list([0,1]): count_1 += 1\n","        elif list(arr[i])== list([1,0]): count_0 += 1\n","    print(count_0, count_1)\n","    return count_0, count_1\n","\n","c_0, c_1 = count_label_dist(train_y)\n","c_0, c_1 = count_label_dist(val_y)\n","c_0, c_1 = count_label_dist(test_y)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["37674 42010\n","4088 5882\n","5080 4905\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T5Zj_5QazJ2s"},"source":["train_x = np.array(train_x).reshape(len(train_x), 30, 23)\n","test_x  = np.array(test_x).reshape(len(test_x), 30, 23)\n","val_x   = np.array(val_x).reshape(len(val_x), 30, 23)\n","train_y = np.array(train_y).reshape(len(train_y),2)\n","test_y  = np.array(test_y).reshape(len(test_y),2)\n","val_y   = np.array(val_y).reshape(len(val_y),2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GM1Jlq5kj3sA"},"source":["# train_x[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RghARJ2W_Pdy"},"source":["def new_multi1_model(input_shape, n_classes):\n","    model = Sequential()\n","\n","    model.add(BatchNormalization(input_shape=(input_shape[0],input_shape[1])))\n","    model.add(Conv1D(filters=80,kernel_size=3,padding='valid',activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    #model.add(Dropout(0.2))\n","    \n","    model.add(BatchNormalization())\n","    model.add(Conv1D(filters=80,kernel_size=5,padding='valid',activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    #model.add(Dropout(0.2))\n","    \n","    model.add(BatchNormalization())\n","    model.add(Conv1D(filters=80,kernel_size=7,padding='valid',activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    #model.add(Dropout(0.2))\n","    \n","    model.add(BatchNormalization())\n","    model.add(Conv1D(filters=80,kernel_size=9,padding='valid',activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    #model.add(Dropout(0.2))\n","\n","    model.add(BatchNormalization())\n","    model.add(Flatten())\n","    model.add(Dense(500,activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","\n","    model.add(BatchNormalization())\n","    model.add(Flatten())\n","    model.add(Dense(40,activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","\n","    model.add(BatchNormalization())\n","    model.add(Dense(2, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","\n","    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=10000, decay_rate=0.9)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=lr_schedule), metrics=['accuracy'])\n","    #model.compile(loss=mycrossentropy, optimizer=Adamax(learning_rate=0.0001), metrics=['accuracy'])\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lpPSNOjyqyCO"},"source":["def lstm_model(input_shape , n_classes):\n","    model = Sequential()\n","    model.add(BatchNormalization(input_shape=(input_shape[0],input_shape[1])))\n","    model.add(LSTM(100,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(50,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(25,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(12,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(6,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(3,return_sequences=True))\n","    model.add(Flatten())\n","    model.add(BatchNormalization())\n","    model.add(Dense(90, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(10, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(2, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=10000, decay_rate=0.9)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=lr_schedule), metrics=['accuracy'])\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8gIDe7xBsiqF"},"source":["def lstm2_model(input_shape , n_classes):\n","    model = Sequential()\n","    model.add(BatchNormalization(input_shape=(input_shape[0],input_shape[1])))\n","    model.add(LSTM(100,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(100,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(50,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(50,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(25,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(12,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(6,return_sequences=True))\n","    model.add(Flatten())\n","    model.add(BatchNormalization())\n","    model.add(Dense(90, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(2, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=10000, decay_rate=0.9)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=lr_schedule), metrics=['accuracy'])\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TdKSs2iKsi0G"},"source":["def lstm3_model(input_shape , n_classes):\n","    model = Sequential()\n","    model.add(BatchNormalization(input_shape=(input_shape[0],input_shape[1])))\n","    model.add(LSTM(50,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(25,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(12,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(6,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(3,return_sequences=True))\n","    model.add(Flatten())\n","    model.add(BatchNormalization())\n","    model.add(Dense(90, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(10, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(2, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=10000, decay_rate=0.9)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=lr_schedule), metrics=['accuracy'])\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4fHO6aq25hc"},"source":["def lstm4_model(input_shape , n_classes):\n","    model = Sequential()\n","    model.add(BatchNormalization(input_shape=(input_shape[0],input_shape[1])))\n","    model.add(LSTM(25,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(12,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(6,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(3,return_sequences=True))\n","    model.add(Flatten())\n","    model.add(BatchNormalization())\n","    model.add(Dense(90, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(25, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(2, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=100000, decay_rate=0.9)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=lr_schedule), metrics=['accuracy'])\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kIS6Quux46zg"},"source":["def lstm5_model(input_shape , n_classes):\n","    model = Sequential()\n","    model.add(BatchNormalization(input_shape=(input_shape[0],input_shape[1])))\n","    model.add(LayerNormalization())\n","    model.add(LSTM(23,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LayerNormalization())\n","    model.add(LSTM(2,return_sequences=True))\n","    model.add(Flatten())\n","    model.add(BatchNormalization())\n","    model.add(LayerNormalization())\n","    model.add(Dense(2, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=50, decay_rate=0.9)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=lr_schedule), metrics=['accuracy'])\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R0dh_ae9Tetl"},"source":["def lstm6_model(input_shape , n_classes):\n","    model = Sequential()\n","    model.add(BatchNormalization(input_shape=(input_shape[0],input_shape[1])))\n","    model.add(LSTM(50,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(25,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(12,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(6,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(3,return_sequences=True))\n","    model.add(Flatten())\n","    model.add(BatchNormalization())\n","    model.add(Dense(90, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(25, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(2, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=100000, decay_rate=0.9)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=lr_schedule), metrics=['accuracy'])\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"apZxa8RmIovx"},"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"izcRpwFJ_XSb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604196361997,"user_tz":-480,"elapsed":525678,"user":{"displayName":"Haren Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjM7LUGwDdn3CACBmSa5bdxiAwKb6p7ehD49gbxuA=s64","userId":"06735001407493510827"}},"outputId":"517f624e-fac1-459d-bb92-cd78d135aac0"},"source":["# tf.keras.backend.clear_session()\n","# model = new_multi1_model((30, 23), 2)\n","model = lstm4_model((30, 23), 2)\n","callback = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"auto\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","batch_normalization (BatchNo (None, 30, 23)            92        \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 30, 25)            4900      \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 30, 25)            100       \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 30, 12)            1824      \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 30, 12)            48        \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 30, 6)             456       \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 30, 6)             24        \n","_________________________________________________________________\n","lstm_3 (LSTM)                (None, 30, 3)             120       \n","_________________________________________________________________\n","flatten (Flatten)            (None, 90)                0         \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 90)                360       \n","_________________________________________________________________\n","dense (Dense)                (None, 90)                8190      \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 90)                360       \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 25)                2275      \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 25)                100       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 2)                 52        \n","=================================================================\n","Total params: 18,901\n","Trainable params: 18,359\n","Non-trainable params: 542\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ePqF6WjR_ZTa"},"source":["history = model.fit(train_x, train_y , epochs=150, batch_size= 256, validation_data=(val_x, val_y), callbacks=[callback, tensorboard_callback] )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h8XO87pLJxKD"},"source":["# %tensorboard --logdir logs\n","# count = 0\n","# correct_0 = 0\n","# correct_1 = 0\n","# pred_0 = 0\n","# pred_1 = 0\n","# for i in range(len(test_x)):\n","#     prediction = model.predict(test_x[i].reshape(1,30,23))\n","#     ans = classes[np.argmax(prediction)]\n","#     if int(ans) == 0 : pred_0 +=1\n","#     else: pred_1 +=1\n","#     if int(ans) == int(classes[np.argmax(test_y[i])]): \n","#       count +=1\n","#       if int(ans) == 0 : correct_0 += 1\n","#       else: correct_1 += 1\n","#     if i is not 0 and i%1000 == 0 : print(\"Accuracy: \", count/i)\n","# print(\"Accuracy: \", count/len(test_x))\n","# print(correct_0, correct_1)\n","# print(pred_0, pred_1)\n","# print(correct_0/pred_0, correct_1/pred_1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fs9bvacs2l6_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604198041044,"user_tz":-480,"elapsed":324696,"user":{"displayName":"Haren Lin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjM7LUGwDdn3CACBmSa5bdxiAwKb6p7ehD49gbxuA=s64","userId":"06735001407493510827"}},"outputId":"fa7052b1-572f-4de1-984f-b40f588c0661"},"source":["prediction_y = []\n","truth_y = []\n","for i in range(len(test_y)):\n","  prediction_y.append(int(classes[np.argmax(model.predict(test_x[i].reshape(1,30,23)))]))\n","  truth_y.append(int(classes[np.argmax(test_y[i])]))\n","print(\"Accuracy: \")\n","print( 1 - (np.sum(np.logical_xor(np.array(prediction_y), np.array(truth_y))))/len(test_y) )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy: \n","0.8800200300450676\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H6mtR0zSwAhH"},"source":["model.save('/content/drive/My Drive/Program_Trading_Code/lstm4_only_price.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8zEp0sfowDDP"},"source":["#選定欲回測的model\n","from keras.models import load_model\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('max_colwidth',100)\n","model = load_model('/content/drive/My Drive/Program_Trading_Code/lstm4_5_5.h5')\n","\n","stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\",\n","            \"2105\", \"2207\", #\"2227\", \n","            \"2301\", \"2303\", \"2308\", \"2317\", \"2327\",\n","            \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\",\n","            \"2633\", \"2801\", \"2823\", \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\",\n","            \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\",\n","            \"4904\", \"4938\", \"5871\", \"5880\", \"6505\", \"9904\", \"9910\"]\n","# stockNum = [\"2330\"]\n","\n","#設定 股票資料\n","start = '2018/08/01'\n","end = '2019/06/3'\n","# start = '2019/06/4'\n","# end = '2020/11/11'\n","s = start.split('/')\n","e = end.split('/')\n","start = datetime.datetime(int(s[0]), int(s[1]), int(s[2]))\n","end = datetime.datetime(int(e[0]), int(e[1]), int(e[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fG8aO0QuxbQL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605702491200,"user_tz":-480,"elapsed":807979,"user":{"displayName":"王成中","photoUrl":"","userId":"06411389530591681249"}},"outputId":"314f3fb0-5647-47ff-8f67-3b1a7fc523ac"},"source":["wala_wala = 0\n","wala_wala_our = 0\n","wala_wala_origin = 0\n","\n","Dict_vic = {}\n","Dict_return={}\n","for stock_num in stockNum:\n","  #先算出之後回測用的價位\n","  Price_df = pdr.DataReader(str(stock_num)+'.TW', 'yahoo', start=start, end=end)\n","  Price_df.index = Price_df.index.format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n","  #融資表格\n","  stock_time = str(Price_df.index[0]).split(\" \")[0]\n","  # print(stock_time)\n","  #load in 融資融券\n","  url = \"https://api.finmindtrade.com/api/v3/data\"\n","  parameter = {\n","    \"dataset\": \"TaiwanStockMarginPurchaseShortSale\",\n","    \"stock_id\": str(stock_num),\n","    \"date\": stock_time,\n","  }\n","  data = requests.get(url, params=parameter)\n","  data = data.json()\n","  data = pd.DataFrame(data['data'])\n","  data['b_total'] = data['MarginPurchaseLimit'] - data['MarginPurchaseTodayBalance']\n","  data['s_total'] = data['ShortSaleLimit'] - data['ShortSaleTodayBalance']\n","  data['b_s_ratio'] = (data['ShortSaleLimit'] - data['ShortSaleTodayBalance'])/(data['MarginPurchaseLimit'] - data['MarginPurchaseTodayBalance']+1)\n","  data = data.set_index('date')\n","  # 合併這兩個表格\n","  new_df = Price_df.join(data)\n","  new_df = new_df.drop(['stock_id'], axis=1)\n","  new_df = new_df.drop(['ShortSaleCashRepayment'], axis=1)\n","  # 處理三大法人投資情況 視情況加入\n","  url = \"https://api.finmindtrade.com/api/v3/data\"\n","  parameter = {\n","    \"dataset\": \"InstitutionalInvestorsBuySell\",\n","    \"stock_id\": str(stock_num),\n","    \"date\": stock_time,\n","  }\n","  data = requests.get(url, params=parameter)\n","  data = data.json()\n","  data = pd.DataFrame(data['data'])\n","  df = pd.DataFrame()\n","  z = 0 \n","  i = 0\n","  while i < len(data)  :\n","    a = data['date'][i]\n","    count = 0\n","    sell = 0\n","    buy = 0 \n","    if i+6 < len(data)-1:\n","        for j  in range(i, i+6):\n","            if data['date'][j]== a :\n","              count += 1\n","              sell += data['sell'][j]\n","              buy += data['buy'][j]\n","    else:\n","      for j in range(i, len(data)):\n","        if data['date'][j] == a :\n","          count += 1\n","          sell += data['sell'][j]\n","          buy += data['buy'][j]\n","    df = df.append({'date': a, 'buy_volume': buy, 'sell_volume':sell, 'bs_ratio':buy/(sell+1)}, ignore_index=True)\n","    i+=count\n","  new_df = new_df.join(df.set_index('date'))\n","  new_df = new_df.fillna(axis=0,method='ffill')\n","  new_df = new_df.drop(['Note'], axis=1)\n","  # gpy = data.groupby('date').sum()\n","  # gpy.rename(columns={'buy':'buy_volume', 'sell': 'sell_volume'}, inplace=True)\n","  # gpy['bs_ratio'] = gpy['buy_volume'] / (gpy['sell_volume']+1)\n","  # df = gpy\n","  # new_df = new_df.join(df)\n","  # new_df = new_df.dropna(axis=0, how='any')\n","  # new_df = new_df.drop(['Note'], axis=1)\n","  new_df.reset_index(drop=True, inplace=True)\n","  for columnName in new_df.columns:\n","    if str(columnName) == 'y_label' or str(columnName) == 'index': continue\n","    # print(columnName)\n","    new_df[str(columnName)] = exponential_smoothing(5, 0.2, list(new_df[str(columnName)]))\n","    days = 10\n","    ans = [0]*days\n","    for i in range(days,len(new_df)):\n","      Pi = new_df['Close'][i]\n","      Pj = new_df['Close'][i-days]\n","      if Pi > Pj : y = 1\n","      else: y = 0\n","      ans.append(y)\n","  new_df['y_label']= ans\n","  #更改index 將日期更改為\n","  new_df = new_df.reset_index()\n","  new_df.rename(columns={'index':'Date'}, inplace=True)\n","  time_list = list(new_df['Date'])\n","  new_df = new_df.drop(['Date'], axis=1)\n","  new_df = new_df.drop(['MarginPurchaseLimit'], axis=1)\n","  new_df = new_df.drop(['ShortSaleLimit'], axis=1)\n","  # new_df = new_df.drop(['level_0'], axis=1)\n","  Price_df = Price_df.reset_index()\n","\n","  # start evaluaion \n","  ###############一般回測################################\n","  left_money = 10**6\n","  own_asset = 10**6\n","  time_slide = 30 \n","  own_stock = 0 \n","  money_record = [left_money]*time_slide\n","  # flag = 0 \n","  origin_money = 10**6 #紀錄開場進最後出\n","  origin_hold_stock = 0 \n","\n","  base_victory = 0 \n","  count_victory = 0 \n","  temporary = 0\n","\n","  for i in range(time_slide, len(new_df)): \n","    tmp = new_df[i-time_slide:i]\n","    for col in new_df.columns:\n","      if col == 'Date' or col == 'y_label' or col =='bs_ratio' or col =='b_s_ratio': continue\n","      mean = statistics.mean(tmp[str(col)])\n","      stdev = statistics.stdev(tmp[str(col)])\n","      if stdev == 0: stdev = 1\n","      def test(s): \n","        return (float(s)-mean)/stdev\n","      tmp[str(col)].map(test)\n","    x = np.array(np.array(tmp).tolist()[0: time_slide]).reshape(time_slide,len(tmp.columns))\n","    predict = int(classes[np.argmax(model.predict(x.reshape(1,30,23)))])\n","    price = int(Price_df['Close'][i]*100)/100\n","    if i == time_slide: #起始買\n","      origin_hold_stock += int( left_money / ( price * (1 + 0.001425)) ) # 包含手續費可以購買的股數\n","      origin_money = origin_money - origin_hold_stock*price*(1 + 0.001425)\n","    elif i == len(new_df)-1: #結束賣\n","      origin_money = origin_money + origin_hold_stock*price*(1 - 0.001425 - 0.003)\n","    if predict == 1:\n","      if own_stock ==0:\n","        # print(\"買入\")\n","        own_stock += int( left_money / ( price * (1 + 0.001425)) )\n","        left_money = left_money - own_stock*price*(1 + 0.001425)\n","        # print(\"目前價格： \" , price, \"日期: \",time_list[i])\n","        # print(\"現有資產： \", (left_money+own_stock*price),\"擁有股票：\", own_stock, \"資金部分： \", left_money)\n","        temporary =  price\n","\n","    elif predict == 0 :\n","      if own_stock > 0:\n","        # print(\"賣出\")\n","        left_money += own_stock*price*(1 - 0.001425 - 0.003)\n","        own_stock = 0\n","        # print(\"目前價格： \" , price, \"日期: \", time_list[i])\n","        # print(\"現有資產： \", (left_money+own_stock*price),\"擁有股票：\", own_stock, \"資金部分： \", left_money)\n","        if price > temporary:\n","          count_victory +=1\n","        base_victory +=1\n","    money_record.append(left_money+own_stock*price)\n","  print(str(stock_num)+\"最後資產 ：\", int(money_record[-1]),\"報酬率：\",(int(money_record[-1])-(10**6))*100/(10**6),\"%\")\n","  print(str(stock_num)+\"最後資產 ：\", int(origin_money),\"報酬率：\",(int(origin_money)-(10**6))*100/(10**6),\"%（開場進 最後出）\")\n","  print(str(stock_num)+\"validation 勝率：\", count_victory/base_victory,'(',count_victory,'/',base_victory ,')')\n","  \n","  Dict_return[str(stock_num)] = (int(money_record[-1])-(10**6))*100/(10**6)\n","  Dict_vic[str(stock_num)] = count_victory/base_victory\n","\n","  wala_wala += 10**6\n","  wala_wala_our += int(money_record[-1])\n","  wala_wala_origin += int(origin_money)\n","print(\"測試結束\")\n","print(\"our總投資報酬率：\", (wala_wala_our - wala_wala)*100 / wala_wala, \"%\")\n","print(\"origin總投資報酬率：\", (wala_wala_origin - wala_wala)*100 / wala_wala, \"%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1101最後資產 ： 913904 報酬率： -8.6096 %\n","1101最後資產 ： 1111544 報酬率： 11.1544 %（開場進 最後出）\n","1101validation 勝率： 0.42857142857142855 ( 3 / 7 )\n","1102最後資產 ： 1101097 報酬率： 10.1097 %\n","1102最後資產 ： 1247586 報酬率： 24.7586 %（開場進 最後出）\n","1102validation 勝率： 0.7142857142857143 ( 5 / 7 )\n","1216最後資產 ： 992065 報酬率： -0.7935 %\n","1216最後資產 ： 1052713 報酬率： 5.2713 %（開場進 最後出）\n","1216validation 勝率： 0.3333333333333333 ( 2 / 6 )\n","1301最後資產 ： 905646 報酬率： -9.4354 %\n","1301最後資產 ： 976246 報酬率： -2.3754 %（開場進 最後出）\n","1301validation 勝率： 0.3333333333333333 ( 2 / 6 )\n","1326最後資產 ： 820529 報酬率： -17.9471 %\n","1326最後資產 ： 897276 報酬率： -10.2724 %（開場進 最後出）\n","1326validation 勝率： 0.2 ( 1 / 5 )\n","1402最後資產 ： 887077 報酬率： -11.2923 %\n","1402最後資產 ： 919563 報酬率： -8.0437 %（開場進 最後出）\n","1402validation 勝率： 0.6 ( 3 / 5 )\n","2002最後資產 ： 904523 報酬率： -9.5477 %\n","2002最後資產 ： 990474 報酬率： -0.9526 %（開場進 最後出）\n","2002validation 勝率： 0.5714285714285714 ( 4 / 7 )\n","2105最後資產 ： 779513 報酬率： -22.0487 %\n","2105最後資產 ： 849971 報酬率： -15.0029 %（開場進 最後出）\n","2105validation 勝率： 0.16666666666666666 ( 1 / 6 )\n","2207最後資產 ： 1756757 報酬率： 75.6757 %\n","2207最後資產 ： 1972560 報酬率： 97.256 %（開場進 最後出）\n","2207validation 勝率： 0.75 ( 3 / 4 )\n","2301最後資產 ： 1139152 報酬率： 13.9152 %\n","2301最後資產 ： 1263989 報酬率： 26.3989 %（開場進 最後出）\n","2301validation 勝率： 0.5714285714285714 ( 4 / 7 )\n","2303最後資產 ： 986026 報酬率： -1.3974 %\n","2303最後資產 ： 839771 報酬率： -16.0229 %（開場進 最後出）\n","2303validation 勝率： 0.3333333333333333 ( 3 / 9 )\n","2308最後資產 ： 957288 報酬率： -4.2712 %\n","2308最後資產 ： 1275750 報酬率： 27.575 %（開場進 最後出）\n","2308validation 勝率： 0.5 ( 3 / 6 )\n","2317最後資產 ： 1121610 報酬率： 12.161 %\n","2317最後資產 ： 741636 報酬率： -25.8364 %（開場進 最後出）\n","2317validation 勝率： 0.6 ( 3 / 5 )\n","2327最後資產 ： 916033 報酬率： -8.3967 %\n","2327最後資產 ： 496202 報酬率： -50.3798 %（開場進 最後出）\n","2327validation 勝率： 0.5 ( 2 / 4 )\n","2330最後資產 ： 926358 報酬率： -7.3642 %\n","2330最後資產 ： 889217 報酬率： -11.0783 %（開場進 最後出）\n","2330validation 勝率： 0.3333333333333333 ( 2 / 6 )\n","2352最後資產 ： 992763 報酬率： -0.7237 %\n","2352最後資產 ： 968797 報酬率： -3.1203 %（開場進 最後出）\n","2352validation 勝率： 0.5 ( 3 / 6 )\n","2357最後資產 ： 754010 報酬率： -24.599 %\n","2357最後資產 ： 835906 報酬率： -16.4094 %（開場進 最後出）\n","2357validation 勝率： 0.25 ( 2 / 8 )\n","2382最後資產 ： 1134822 報酬率： 13.4822 %\n","2382最後資產 ： 1144593 報酬率： 14.4593 %（開場進 最後出）\n","2382validation 勝率： 0.5 ( 2 / 4 )\n","2395最後資產 ： 1043062 報酬率： 4.3062 %\n","2395最後資產 ： 1216841 報酬率： 21.6841 %（開場進 最後出）\n","2395validation 勝率： 0.5 ( 3 / 6 )\n","2408最後資產 ： 847052 報酬率： -15.2948 %\n","2408最後資產 ： 1054775 報酬率： 5.4775 %（開場進 最後出）\n","2408validation 勝率： 0.4 ( 2 / 5 )\n","2412最後資產 ： 1002369 報酬率： 0.2369 %\n","2412最後資產 ： 1021269 報酬率： 2.1269 %（開場進 最後出）\n","2412validation 勝率： 0.2857142857142857 ( 2 / 7 )\n","2454最後資產 ： 879122 報酬率： -12.0878 %\n","2454最後資產 ： 1267109 報酬率： 26.7109 %（開場進 最後出）\n","2454validation 勝率： 0.2857142857142857 ( 2 / 7 )\n","2474最後資產 ： 892183 報酬率： -10.7817 %\n","2474最後資產 ： 553040 報酬率： -44.696 %（開場進 最後出）\n","2474validation 勝率： 0.5 ( 2 / 4 )\n","2609最後資產 ： 943017 報酬率： -5.6983 %\n","2609最後資產 ： 930206 報酬率： -6.9794 %（開場進 最後出）\n","2609validation 勝率： 0.4 ( 4 / 10 )\n","2610最後資產 ： 1168774 報酬率： 16.8774 %\n","2610最後資產 ： 1045971 報酬率： 4.5971 %（開場進 最後出）\n","2610validation 勝率： 0.5714285714285714 ( 4 / 7 )\n","2633最後資產 ： 1446408 報酬率： 44.6408 %\n","2633最後資產 ： 1731173 報酬率： 73.1173 %（開場進 最後出）\n","2633validation 勝率： 1.0 ( 7 / 7 )\n","2801最後資產 ： 952817 報酬率： -4.7183 %\n","2801最後資產 ： 1101382 報酬率： 10.1382 %（開場進 最後出）\n","2801validation 勝率： 0.42857142857142855 ( 3 / 7 )\n","2823最後資產 ： 831807 報酬率： -16.8193 %\n","2823最後資產 ： 822050 報酬率： -17.795 %（開場進 最後出）\n","2823validation 勝率： 0.0 ( 0 / 4 )\n","2880最後資產 ： 1056272 報酬率： 5.6272 %\n","2880最後資產 ： 1163243 報酬率： 16.3243 %（開場進 最後出）\n","2880validation 勝率： 0.5714285714285714 ( 4 / 7 )\n","2881最後資產 ： 846692 報酬率： -15.3308 %\n","2881最後資產 ： 878140 報酬率： -12.186 %（開場進 最後出）\n","2881validation 勝率： 0.16666666666666666 ( 1 / 6 )\n","2882最後資產 ： 799814 報酬率： -20.0186 %\n","2882最後資產 ： 815975 報酬率： -18.4025 %（開場進 最後出）\n","2882validation 勝率： 0.2 ( 1 / 5 )\n","2883最後資產 ： 889625 報酬率： -11.0375 %\n","2883最後資產 ： 856082 報酬率： -14.3918 %（開場進 最後出）\n","2883validation 勝率： 0.2 ( 1 / 5 )\n","2884最後資產 ： 1216132 報酬率： 21.6132 %\n","2884最後資產 ： 1224732 報酬率： 22.4732 %（開場進 最後出）\n","2884validation 勝率： 0.5 ( 2 / 4 )\n","2885最後資產 ： 958748 報酬率： -4.1252 %\n","2885最後資產 ： 1160870 報酬率： 16.087 %（開場進 最後出）\n","2885validation 勝率： 0.4 ( 2 / 5 )\n","2886最後資產 ： 1183774 報酬率： 18.3774 %\n","2886最後資產 ： 1181132 報酬率： 18.1132 %（開場進 最後出）\n","2886validation 勝率： 0.6666666666666666 ( 2 / 3 )\n","2887最後資產 ： 939204 報酬率： -6.0796 %\n","2887最後資產 ： 991221 報酬率： -0.8779 %（開場進 最後出）\n","2887validation 勝率： 0.5 ( 2 / 4 )\n","2888最後資產 ： 825096 報酬率： -17.4904 %\n","2888最後資產 ： 754072 報酬率： -24.5928 %（開場進 最後出）\n","2888validation 勝率： 0.25 ( 2 / 8 )\n","2890最後資產 ： 1065775 報酬率： 6.5775 %\n","2890最後資產 ： 1111116 報酬率： 11.1116 %（開場進 最後出）\n","2890validation 勝率： 0.5 ( 3 / 6 )\n","2891最後資產 ： 852700 報酬率： -14.73 %\n","2891最後資產 ： 974932 報酬率： -2.5068 %（開場進 最後出）\n","2891validation 勝率： 0.2857142857142857 ( 2 / 7 )\n","2892最後資產 ： 1024412 報酬率： 2.4412 %\n","2892最後資產 ： 1101499 報酬率： 10.1499 %（開場進 最後出）\n","2892validation 勝率： 0.3333333333333333 ( 1 / 3 )\n","2912最後資產 ： 837026 報酬率： -16.2974 %\n","2912最後資產 ： 857608 報酬率： -14.2392 %（開場進 最後出）\n","2912validation 勝率： 0.16666666666666666 ( 1 / 6 )\n","3008最後資產 ： 1004110 報酬率： 0.411 %\n","3008最後資產 ： 865569 報酬率： -13.4431 %（開場進 最後出）\n","3008validation 勝率： 0.3333333333333333 ( 2 / 6 )\n","3045最後資產 ： 1023242 報酬率： 2.3242 %\n","3045最後資產 ： 1076242 報酬率： 7.6242 %（開場進 最後出）\n","3045validation 勝率： 0.5714285714285714 ( 4 / 7 )\n","3711最後資產 ： 792464 報酬率： -20.7536 %\n","3711最後資產 ： 830931 報酬率： -16.9069 %（開場進 最後出）\n","3711validation 勝率： 0.5 ( 3 / 6 )\n","4904最後資產 ： 1022686 報酬率： 2.2686 %\n","4904最後資產 ： 1060487 報酬率： 6.0487 %（開場進 最後出）\n","4904validation 勝率： 0.5714285714285714 ( 4 / 7 )\n","4938最後資產 ： 995381 報酬率： -0.4619 %\n","4938最後資產 ： 838805 報酬率： -16.1195 %（開場進 最後出）\n","4938validation 勝率： 0.5 ( 2 / 4 )\n","5871最後資產 ： 989037 報酬率： -1.0963 %\n","5871最後資產 ： 1182038 報酬率： 18.2038 %（開場進 最後出）\n","5871validation 勝率： 0.5 ( 4 / 8 )\n","5880最後資產 ： 1014831 報酬率： 1.4831 %\n","5880最後資產 ： 1120030 報酬率： 12.003 %（開場進 最後出）\n","5880validation 勝率： 0.6 ( 3 / 5 )\n","6505最後資產 ： 840230 報酬率： -15.977 %\n","6505最後資產 ： 896704 報酬率： -10.3296 %（開場進 最後出）\n","6505validation 勝率： 0.0 ( 0 / 7 )\n","9904最後資產 ： 1049289 報酬率： 4.9289 %\n","9904最後資產 ： 1151957 報酬率： 15.1957 %（開場進 最後出）\n","9904validation 勝率： 0.5 ( 2 / 4 )\n","9910最後資產 ： 858258 報酬率： -14.1742 %\n","9910最後資產 ： 1224943 報酬率： 22.4943 %（開場進 最後出）\n","9910validation 勝率： 0.2857142857142857 ( 2 / 7 )\n","測試結束\n","our總投資報酬率： -1.8027803921568628 %\n","origin總投資報酬率： 3.011643137254902 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i9FacETPTBPx"},"source":["# plt.plot(time_list, money_record)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lqz0_oo8TBzn"},"source":["pd.options.mode.chained_assignment = None \n","dic = {}\n","from keras.models import load_model\n","from sklearn.metrics import accuracy_score\n","model = load_model('/content/drive/My Drive/Program_Trading_Code/lstm4_5_5(1025-1000).h5')\n","#model = load_model('/content/drive/My Drive/Program_Trading_Code/lstm4_only_price.h5')\n","TEST_Y = []\n","TRUTH_Y = []\n","for stockno in stockNum:\n","  train_x = []\n","  test_x = []\n","  val_x = []\n","  train_y = []\n","  test_y = []\n","  val_y = []\n","  x = []\n","  if int(stockno) == 2227: continue\n","  df = pd.read_csv('/content/drive/My Drive/Program_Trading_Code/0050_stock_5_5/'+str(stockno)+'.csv')\n","  record = pd.read_csv('/content/drive/My Drive/Program_Trading_Code/0050_stock_5_5/'+str(stockno)+'mean&stdev.csv')\n","  df.rename(columns={'Unnamed: 0':'Date'}, inplace=True)\n","  df = df.drop(['Date'], axis=1)\n","  df = df.drop(['MarginPurchaseLimit'], axis=1)\n","  df = df.drop(['ShortSaleLimit'], axis=1)\n","  df = df.dropna(axis=0, how='any')\n","  df.reset_index(drop=True, inplace=True)\n","  days_before = 30\n","  for i in range(days_before, len(df)):\n","      tmp = df[i-days_before:i]\n","      for col in df.columns:\n","        if col == 'Date' or col == 'y_label' or col =='bs_ratio' or col =='b_s_ratio': continue\n","        mean = record[str(col)+'_mean'][i-days_before]\n","        stdev = record[str(col)+'_stdev'][i-days_before]\n","        def test(s): \n","          return (float(s)-mean)/stdev\n","        tmp[str(col)].map(test)\n","      x.append( np.array(np.array(tmp).tolist()[0: days_before]).reshape(days_before,len(tmp.columns)))\n","  y = list(df['y_label'][days_before:]) \n","  #train:val:test = 8:1:1\n","  tr_va = int(len(x)*8/10)\n","  va_te = int(len(x)*9/10)\n","  # print(\"no: \", tr_va, \"no: \", va_te, \"leng: \", len(y))\n","  train_x = train_x + x[:tr_va]\n","  train_y = train_y + y[:tr_va]\n","  val_x = val_x + x[tr_va: va_te]\n","  val_y = val_y + y[tr_va: va_te]\n","  test_x = test_x + x[va_te:]\n","  test_y = test_y + y[va_te:]\n","  print(str(stockno)+\" loaded....\")\n","  # print(len(train_x), len(val_x), len(test_x))\n","  prediction_y = []\n","  truth_y = []\n","  for i in range(len(val_x)):\n","    prediction_y.append(int(classes[np.argmax(model.predict(val_x[i].reshape(1,30,23)))]))\n","    #此處無需做argmax 因為load進時沒有做 to_onelist\n","    truth_y.append(val_y[i])\n","  TEST_Y += prediction_y\n","  TRUTH_Y += truth_y\n","  accuracy = accuracy_score(np.array(prediction_y), np.array(truth_y))\n","  print(\"Validation Accuracy: \", accuracy)\n","  dic[str(stockno)] = accuracy\n","print(\"================================total accuracy: \")\n","print(accuracy_score(np.array(TEST_Y), np.array(TRUTH_Y)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPBThNP_6fcG"},"source":["# accuracy = 1 - (np.sum(np.logical_xor(np.array(TEST_Y), np.array(TRUTH_Y))))/len(TEST_Y) \n","# print(accuracy)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kJZco2rxW4O_"},"source":["Validation Find 投資報酬率 & 計算權重"]},{"cell_type":"code","metadata":{"id":"wdEmzftTZgFm"},"source":["#選定欲回測的model\n","from keras.models import load_model\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('max_colwidth',100)\n","model = load_model('/content/drive/My Drive/Program_Trading_Code/lstm4_5_5.h5')\n","#model = load_model('/content/drive/My Drive/Program_Trading_Code/lstm4_only_price.h5')\n","\n","stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\",\n","            \"2105\", \"2207\", #\"2227\", \n","            \"2301\", \"2303\", \"2308\", \"2317\", \"2327\",\n","            \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\",\n","            \"2633\", \"2801\", \"2823\", \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\",\n","            \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\",\n","            \"4904\", \"4938\", \"5871\", \"5880\", \"6505\", \"9904\", \"9910\"]\n","\n","#設定 股票資料\n","#start = '2019/05/13'\n","start = '2018/08/01'\n","end = '2019/06/03'\n","#end = '2020/09/21'\n","s = start.split('/')\n","e = end.split('/')\n","start = datetime.datetime(int(s[0]), int(s[1]), int(s[2]))\n","end = datetime.datetime(int(e[0]), int(e[1]), int(e[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"27zlR22TbB_c"},"source":["wala_wala = 0\n","wala_wala_our = 0\n","wala_wala_origin = 0\n","#asset_at_the_start = 5.1 * 10**7\n","DIC_ROR = {}\n","for stock_num in stockNum:\n","  #先算出之後回測用的價位\n","  Price_df = pdr.DataReader(str(stock_num)+'.TW', 'yahoo', start=start, end=end)\n","  Price_df.index = Price_df.index.format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n","  #融資表格\n","  stock_time = str(Price_df.index[0]).split(\" \")[0]\n","  # print(stock_time)\n","  #load in 融資融券\n","  url = \"https://api.finmindtrade.com/api/v3/data\"\n","  parameter = {\n","    \"dataset\": \"TaiwanStockMarginPurchaseShortSale\",\n","    \"stock_id\": str(stock_num),\n","    \"date\": stock_time,\n","  }\n","  data = requests.get(url, params=parameter)\n","  data = data.json()\n","  data = pd.DataFrame(data['data'])\n","  data['b_total'] = data['MarginPurchaseLimit'] - data['MarginPurchaseTodayBalance']\n","  data['s_total'] = data['ShortSaleLimit'] - data['ShortSaleTodayBalance']\n","  data['b_s_ratio'] = (data['ShortSaleLimit'] - data['ShortSaleTodayBalance'])/(data['MarginPurchaseLimit'] - data['MarginPurchaseTodayBalance']+1)\n","  data = data.set_index('date')\n","  # 合併這兩個表格\n","  new_df = Price_df.join(data)\n","  new_df = new_df.drop(['stock_id'], axis=1)\n","  new_df = new_df.drop(['ShortSaleCashRepayment'], axis=1)\n","  # 處理三大法人投資情況 視情況加入\n","  url = \"https://api.finmindtrade.com/api/v3/data\"\n","  parameter = {\n","    \"dataset\": \"InstitutionalInvestorsBuySell\",\n","    \"stock_id\": str(stock_num),\n","    \"date\": stock_time,\n","  }\n","  data = requests.get(url, params=parameter)\n","  data = data.json()\n","  data = pd.DataFrame(data['data'])\n","  df = pd.DataFrame()\n","  z = 0 \n","  i = 0\n","  while i < len(data)  :\n","    a = data['date'][i]\n","    count = 0\n","    sell = 0\n","    buy = 0 \n","    if i+6 < len(data)-1:\n","        for j  in range(i, i+6):\n","            if data['date'][j]== a :\n","              count += 1\n","              sell += data['sell'][j]\n","              buy += data['buy'][j]\n","    else:\n","      for j in range(i, len(data)):\n","        if data['date'][j] == a :\n","          count += 1\n","          sell += data['sell'][j]\n","          buy += data['buy'][j]\n","    df = df.append({'date': a, 'buy_volume': buy, 'sell_volume':sell, 'bs_ratio':buy/(sell+1)}, ignore_index=True)\n","    i+=count\n","  new_df = new_df.join(df.set_index('date'))\n","  new_df = new_df.fillna(axis=0,method='ffill')\n","  new_df = new_df.drop(['Note'], axis=1)\n","  # gpy = data.groupby('date').sum()\n","  # gpy.rename(columns={'buy':'buy_volume', 'sell': 'sell_volume'}, inplace=True)\n","  # gpy['bs_ratio'] = gpy['buy_volume'] / (gpy['sell_volume']+1)\n","  # df = gpy\n","  # new_df = new_df.join(df)\n","  # new_df = new_df.dropna(axis=0, how='any')\n","  # new_df = new_df.drop(['Note'], axis=1)\n","  new_df.reset_index(drop=True, inplace=True)\n","  for columnName in new_df.columns:\n","    if str(columnName) == 'y_label' or str(columnName) == 'index': continue\n","    # print(columnName)\n","    new_df[str(columnName)] = exponential_smoothing(5, 0.2, list(new_df[str(columnName)]))\n","    days = 10\n","    ans = [0]*days\n","    for i in range(days,len(new_df)):\n","      Pi = new_df['Close'][i]\n","      Pj = new_df['Close'][i-days]\n","      if Pi > Pj : y = 1\n","      else: y = 0\n","      ans.append(y)\n","  new_df['y_label']= ans\n","  #更改index 將日期更改為\n","  new_df = new_df.reset_index()\n","  new_df.rename(columns={'index':'Date'}, inplace=True)\n","  time_list = list(new_df['Date'])\n","  new_df = new_df.drop(['Date'], axis=1)\n","  new_df = new_df.drop(['MarginPurchaseLimit'], axis=1)\n","  new_df = new_df.drop(['ShortSaleLimit'], axis=1)\n","  # new_df = new_df.drop(['level_0'], axis=1)\n","  Price_df = Price_df.reset_index()\n","\n","  # start evaluaion \n","  ###############一般回測################################\n","  left_money = 10**6\n","  own_asset = 10**6\n","  time_slide = 30 \n","  own_stock = 0 \n","  money_record = [left_money]*time_slide\n","  origin_money = 10**6 #紀錄開場進最後出\n","  origin_hold_stock = 0 \n","  for i in range(time_slide, len(new_df)): \n","    tmp = new_df[i-time_slide:i]\n","    for col in new_df.columns:\n","      if col == 'Date' or col == 'y_label' or col =='bs_ratio' or col =='b_s_ratio': continue\n","      mean = statistics.mean(tmp[str(col)])\n","      stdev = statistics.stdev(tmp[str(col)])\n","      if stdev == 0: stdev = 1\n","      def test(s): \n","        return (float(s)-mean)/stdev\n","      tmp[str(col)].map(test)\n","    x = np.array(np.array(tmp).tolist()[0: time_slide]).reshape(time_slide,len(tmp.columns))\n","    predict = int(classes[np.argmax(model.predict(x.reshape(1,30,23)))])\n","    price = int(Price_df['Close'][i]*100)/100\n","    if i == time_slide: #起始買\n","      origin_hold_stock += int( left_money / ( price * (1 + 0.001425)) ) # 包含手續費可以購買的股數\n","      origin_money = origin_money - origin_hold_stock*price*(1 + 0.001425)\n","    elif i == len(new_df)-1: #結束賣\n","      origin_money = origin_money + origin_hold_stock*price*(1 - 0.001425 - 0.003)\n","    if predict == 1:\n","      if own_stock ==0:\n","        # print(\"買入\")\n","        own_stock += int( left_money / ( price * (1 + 0.001425)) )\n","        left_money = left_money - own_stock*price*(1 + 0.001425)\n","        # print(\"目前價格： \" , price, \"日期: \",time_list[i])\n","        # print(\"現有資產： \", (left_money+own_stock*price),\"擁有股票：\", own_stock, \"資金部分： \", left_money)\n","    elif predict == 0 :\n","      if own_stock > 0:\n","        # print(\"賣出\")\n","        left_money += own_stock*price*(1 - 0.001425 - 0.003)\n","        own_stock = 0\n","        # print(\"目前價格： \" , price, \"日期: \", time_list[i])\n","        # print(\"現有資產： \", (left_money+own_stock*price),\"擁有股票：\", own_stock, \"資金部分： \", left_money)\n","    money_record.append(left_money+own_stock*price)\n","  print(str(stock_num)+\"最後資產 ：\", int(money_record[-1]),\"報酬率：\",(int(money_record[-1])-(10**6))*100/(10**6),\"%\")\n","  print(str(stock_num)+\"最後資產 ：\", int(origin_money),\"報酬率：\",(int(origin_money)-(10**6))*100/(10**6),\"%（開場進 最後出）\")\n","  #wala_wala_weight += asset_at_the_start * DIC[stock_num]\n","  wala_wala += 10**6\n","  wala_wala_our += int(money_record[-1])\n","  wala_wala_origin += int(origin_money)\n","  DIC_ROR[str(stock_num)] = (int(money_record[-1])-(10**6))*100/(10**6) - (int(origin_money)-(10**6))*100/(10**6)\n","  print(DIC_ROR[str(stock_num)])\n","print(\"測試結束\")\n","print(\"our總投資報酬率：\", (wala_wala_our - wala_wala)*100 / wala_wala, \"%\")\n","# print(\"origin總投資報酬率：\", (wala_wala_origin - wala_wala)*100 / wala_wala, \"%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MIdu5gC3qIZX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605702781707,"user_tz":-480,"elapsed":874,"user":{"displayName":"王成中","photoUrl":"","userId":"06411389530591681249"}},"outputId":"91f0a98e-111b-4273-86e1-990b649e06a7"},"source":["# Dict_vic \n","# Dict_return\n","# Weights_Dict = {}\n","#勝率超過五成 且報酬率為正\n","Weights_Dict = {}\n","for key in Dict_vic:\n","  # print(key, '->', DIC_ROR[key])\n","  if Dict_vic[key] > 0.5 and Dict_return[key] >0:\n","    print(key, '->', Dict_vic[key],\"報酬: \",Dict_return[key] )\n","    Weights_Dict[key] = Dict_return[key]\n","WeightSum = sum(Weights_Dict.values())\n","NewWeightSum = 0\n","for key in Weights_Dict:\n","  Weights_Dict[key] /= WeightSum\n","  print(key, '->', Weights_Dict[key])\n","  NewWeightSum += Weights_Dict[key]\n","print(Weights_Dict)\n","print(NewWeightSum)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1102 -> 0.7142857142857143 報酬:  10.1097\n","2207 -> 0.75 報酬:  75.6757\n","2301 -> 0.5714285714285714 報酬:  13.9152\n","2317 -> 0.6 報酬:  12.161\n","2610 -> 0.5714285714285714 報酬:  16.8774\n","2633 -> 1.0 報酬:  44.6408\n","2880 -> 0.5714285714285714 報酬:  5.6272\n","2886 -> 0.6666666666666666 報酬:  18.3774\n","3045 -> 0.5714285714285714 報酬:  2.3242\n","4904 -> 0.5714285714285714 報酬:  2.2686\n","5880 -> 0.6 報酬:  1.4831\n","1102 -> 0.04968880906987752\n","2207 -> 0.37194332260396756\n","2301 -> 0.06839270363800704\n","2317 -> 0.059770874219688075\n","2610 -> 0.08295180927188255\n","2633 -> 0.2194079139763384\n","2880 -> 0.027657484039883953\n","2886 -> 0.09032425490378224\n","3045 -> 0.011423358758440838\n","4904 -> 0.01115008677368509\n","5880 -> 0.0072893827444469525\n","{'1102': 0.04968880906987752, '2207': 0.37194332260396756, '2301': 0.06839270363800704, '2317': 0.059770874219688075, '2610': 0.08295180927188255, '2633': 0.2194079139763384, '2880': 0.027657484039883953, '2886': 0.09032425490378224, '3045': 0.011423358758440838, '4904': 0.01115008677368509, '5880': 0.0072893827444469525}\n","1.0000000000000002\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"svtsposYYIEg"},"source":["# DIC_ROR = {'1101': -8.6096, '1102': 10.1097, '1216': -0.7935, '1301': -9.4354, '1326': -17.9471, '1402': -11.2923, '2002': -9.5477, '2105': -22.0487, '2207': 75.6757, '2301': 13.9152, '2303': -1.3974, '2308': -4.2712, '2317': 12.161, '2327': -8.3967, '2330': -7.3642, '2352': -0.7237, '2357': -24.599, '2382': 13.4822, '2395': 4.3062, '2408': -15.2948, '2412': 0.2369, '2454': -12.0878, '2474': -10.7817, '2609': -5.6983, '2610': 16.8774, '2633': 44.6408, '2801': -4.7183, '2823': -16.7678, '2880': 5.6272, '2881': -15.3308, '2882': -20.0186, '2883': -11.0375, '2884': 21.6132, '2885': -4.1252, '2886': 18.3774, '2887': -6.0796, '2888': -17.4904, '2890': 6.5775, '2891': -14.73, '2892': 2.4412, '2912': -16.2974, '3008': 0.411, '3045': 2.3242, '3711': -20.7536, '4904': 2.2686, '4938': -0.4619, '5871': -1.0963, '5880': 1.4831, '6505': -15.977, '9904': 4.9289, '9910': -14.1742}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hKJIWycLdcBZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604383622935,"user_tz":-480,"elapsed":1234,"user":{"displayName":"王成中","photoUrl":"","userId":"06411389530591681249"}},"outputId":"eaf19d58-91bc-457c-cba9-29faa18638fb"},"source":["Weights_Dict = {}\n","for key in DIC_ROR:\n","  # print(key, '->', DIC_ROR[key])\n","  if DIC_ROR[key] > 0:\n","    Weights_Dict[key] = DIC_ROR[key]\n","WeightSum = sum(Weights_Dict.values())\n","NewWeightSum = 0\n","for key in Weights_Dict:\n","  Weights_Dict[key] /= WeightSum\n","  print(key, '->', Weights_Dict[key])\n","  NewWeightSum += Weights_Dict[key]\n","print(Weights_Dict)\n","print(NewWeightSum)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2303 -> 0.07721988355903647\n","2317 -> 0.20061911070022445\n","2327 -> 0.2216628555227093\n","2330 -> 0.01960974801043502\n","2352 -> 0.01265359631722586\n","2474 -> 0.17906111223453766\n","2609 -> 0.00676396655344991\n","2610 -> 0.06483766955454759\n","2823 -> 0.005151512111623681\n","2883 -> 0.01771007182127627\n","2886 -> 0.0013949262067141379\n","2888 -> 0.0374993334237941\n","3008 -> 0.07314703694336927\n","4938 -> 0.08266917704105634\n","{'2303': 0.07721988355903647, '2317': 0.20061911070022445, '2327': 0.2216628555227093, '2330': 0.01960974801043502, '2352': 0.01265359631722586, '2474': 0.17906111223453766, '2609': 0.00676396655344991, '2610': 0.06483766955454759, '2823': 0.005151512111623681, '2883': 0.01771007182127627, '2886': 0.0013949262067141379, '2888': 0.0374993334237941, '3008': 0.07314703694336927, '4938': 0.08266917704105634}\n","1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wkRJPPI2X9Nf"},"source":["# lstm_4_5_5\n","Weights_Dict = {'1102': 0.0392674671615576, '2207': 0.2939348412591753, '2301': 0.054048553275221456, '2317': 0.0472349988774842, '2382': 0.05236672164016261, '2395': 0.016725873872726126, '2412': 0.0009201522271257303, '2610': 0.06555414604513213, '2633': 0.17339101536797932, '2880': 0.021856819807859477, '2884': 0.08394864548465104, '2886': 0.0713803526330958, '2890': 0.02554791588822073, '2892': 0.009481957015024621, '3008': 0.0015963806051020478, '3045': 0.009027512901163454, '4904': 0.008811554843636268, '5880': 0.005760564660405955, '9904': 0.019144526434276114}\n","stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\",\n","            \"2105\", \"2207\", \"2227\", \n","            \"2301\", \"2303\", \"2308\", \"2317\", \"2327\", \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\", \"2633\", \"2801\", \"2823\", \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\",\n","            \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\", \"4904\", \"4938\", \"5871\", \"5880\", \"6505\", \"9904\", \"9910\"]\n","Return_Dict = {}\n","for key in stockNum:\n","  if key not in Weights_Dict.keys(): Return_Dict[key] = 0.0\n","  else: Return_Dict[key] = Weights_Dict[key]\n","Return_Weight_df = pd.DataFrame(columns =['Name', 'val'])\n","for key in Return_Dict:\n","  Return_Weight_df = Return_Weight_df.append({'Name': key, 'val': Return_Dict[key]}, ignore_index=True)\n","Return_Weight_df.to_csv('/content/drive/My Drive/Program_Trading_Code/Return_Weight_df.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hRianLl5wxRr"},"source":["# # TESTRORLSTM455 = {\"1102\": -23.165001270379722,\n","# # \"2207\": 96.55600420568851, \"2301\": -9.967695810563841, \"2317\": 0.6622009180339203, \"2382\": 1.4350504721625053, \"2395\": 8.554158169004804, \"2412\": 2.8834341338783886, \n","# # \"2610\": -5.454131307828028, \"2633\": 9.355966715013592, \"2880\": -0.9108505606228517, \"2884\": 14.328480194315958, \"2886\": 6.500115354557333, \"2890\": -17.592412842025244, \n","# # \"2892\": 6.584148629664455, \"3008\": -24.332119510820842, \"3045\": -15.77035459807336, \"4904\": -16.856778896328365, \"5880\": 3.7827719442561625, \"9904\": -29.27592374683791}\n","# # lstm_4_5_5\n","# Weights_Dict = {'1102': 0.0392674671615576, '2207': 0.2939348412591753, '2301': 0.054048553275221456, '2317': 0.0472349988774842, '2382': 0.05236672164016261, '2395': 0.016725873872726126, '2412': 0.0009201522271257303, '2610': 0.06555414604513213, '2633': 0.17339101536797932, '2880': 0.021856819807859477, '2884': 0.08394864548465104, '2886': 0.0713803526330958, '2890': 0.02554791588822073, '2892': 0.009481957015024621, '3008': 0.0015963806051020478, '3045': 0.009027512901163454, '4904': 0.008811554843636268, '5880': 0.005760564660405955, '9904': 0.019144526434276114}\n","# stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\",\n","#             \"2105\", \"2207\", \"2227\", \n","#             \"2301\", \"2303\", \"2308\", \"2317\", \"2327\", \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\", \"2633\", \"2801\", \"2823\", \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\",\n","#             \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\", \"4904\", \"4938\", \"5871\", \"5880\", \"6505\", \"9904\", \"9910\"]\n","# Return_Dict = {}\n","# for key in stockNum:\n","#   if key not in Weights_Dict.keys(): Return_Dict[key] = 0.0\n","#   else: Return_Dict[key] = Weights_Dict[key]\n","# Return_Weight_df = pd.DataFrame(columns =['Name', 'val','Testing_ROR'])\n","# for key in Return_Dict:\n","#   Return_Weight_df = Return_Weight_df.append({'Name': key, 'val': Return_Dict[key]}, ignore_index=True)\n","# Return_Weight_df.to_csv('/content/drive/My Drive/Program_Trading_Code/Return_Weight_df.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0IG4EdnYPTQA"},"source":["#選定欲回測的model\n","from keras.models import load_model\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('max_colwidth',100)\n","model = load_model('/content/drive/My Drive/Program_Trading_Code/lstm4_5_5.h5')\n","#model = load_model('/content/drive/My Drive/Program_Trading_Code/lstm4_only_price.h5')\n","\n","stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\",\n","            \"2105\", \"2207\", #\"2227\", \n","            \"2301\", \"2303\", \"2308\", \"2317\", \"2327\",\n","            \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\",\n","            \"2633\", \"2801\", \"2823\", \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\",\n","            \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\",\n","            \"4904\", \"4938\", \"5871\", \"5880\", \"6505\", \"9904\", \"9910\"]\n","# stockNum = [\"2330\"]\n","\n","#設定 股票資料\n","# start = '2019/05/13'\n","# start = '2018/08/01'\n","start = '2019/06/03'\n","end = '2020/11/11'\n","s = start.split('/')\n","e = end.split('/')\n","start = datetime.datetime(int(s[0]), int(s[1]), int(s[2]))\n","end = datetime.datetime(int(e[0]), int(e[1]), int(e[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7oDMuOgPH9D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605703171938,"user_tz":-480,"elapsed":274711,"user":{"displayName":"王成中","photoUrl":"","userId":"06411389530591681249"}},"outputId":"fa811d5e-b77c-45ee-ece6-987ad49ef99e"},"source":["asset_at_the_start = 19 * 10**6\n","total_asset_present_value = 0\n","for stock_num in stockNum:\n","  if stock_num not in Weights_Dict.keys(): continue\n","  #先算出之後回測用的價位\n","  Price_df = pdr.DataReader(str(stock_num)+'.TW', 'yahoo', start=start, end=end)\n","  Return_Test_Stock_df = Price_df.copy(deep=True)\n","  Price_df.index = Price_df.index.format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n","  stock_time = str(Price_df.index[0]).split(\" \")[0]\n","  url = \"https://api.finmindtrade.com/api/v3/data\" #load in 融資融券\n","  parameter = {\n","    \"dataset\": \"TaiwanStockMarginPurchaseShortSale\",\n","    \"stock_id\": str(stock_num),\n","    \"date\": stock_time,\n","  }\n","  data = requests.get(url, params=parameter)\n","  data = data.json()\n","  data = pd.DataFrame(data['data'])\n","  data['b_total'] = data['MarginPurchaseLimit'] - data['MarginPurchaseTodayBalance']\n","  data['s_total'] = data['ShortSaleLimit'] - data['ShortSaleTodayBalance']\n","  data['b_s_ratio'] = (data['ShortSaleLimit'] - data['ShortSaleTodayBalance'])/(data['MarginPurchaseLimit'] - data['MarginPurchaseTodayBalance']+1)\n","  data = data.set_index('date')\n","  # 合併這兩個表格\n","  new_df = Price_df.join(data)\n","  new_df = new_df.drop(['stock_id'], axis=1)\n","  new_df = new_df.drop(['ShortSaleCashRepayment'], axis=1)\n","  url = \"https://api.finmindtrade.com/api/v3/data\" #load in三大法人投資情況\n","  parameter = {\n","    \"dataset\": \"InstitutionalInvestorsBuySell\",\n","    \"stock_id\": str(stock_num),\n","    \"date\": stock_time,\n","  }\n","  data = requests.get(url, params=parameter)\n","  data = data.json()\n","  data = pd.DataFrame(data['data'])\n","  df = pd.DataFrame()\n","  z = 0 \n","  i = 0\n","  while i < len(data)  :\n","    a = data['date'][i]\n","    count = 0\n","    sell = 0\n","    buy = 0 \n","    if i+6 < len(data)-1:\n","        for j  in range(i, i+6):\n","            if data['date'][j]== a :\n","              count += 1\n","              sell += data['sell'][j]\n","              buy += data['buy'][j]\n","    else:\n","      for j in range(i, len(data)):\n","        if data['date'][j] == a :\n","          count += 1\n","          sell += data['sell'][j]\n","          buy += data['buy'][j]\n","    df = df.append({'date': a, 'buy_volume': buy, 'sell_volume':sell, 'bs_ratio':buy/(sell+1)}, ignore_index=True)\n","    i+=count\n","  new_df = new_df.join(df.set_index('date'))\n","  new_df = new_df.fillna(axis=0,method='ffill')\n","  new_df = new_df.drop(['Note'], axis=1)\n","  new_df.reset_index(drop=True, inplace=True)\n","  for columnName in new_df.columns:\n","    if str(columnName) == 'y_label' or str(columnName) == 'index': continue\n","    new_df[str(columnName)] = exponential_smoothing(5, 0.2, list(new_df[str(columnName)]))\n","    days = 10\n","    ans = [0]*days\n","    for i in range(days,len(new_df)):\n","      Pi = new_df['Close'][i]\n","      Pj = new_df['Close'][i-days]\n","      if Pi > Pj : y = 1\n","      else: y = 0\n","      ans.append(y)\n","  new_df['y_label']= ans\n","  new_df = new_df.reset_index()\n","  new_df.rename(columns={'index':'Date'}, inplace=True)\n","  time_list = list(new_df['Date'])\n","  new_df = new_df.drop(['Date'], axis=1)\n","  new_df = new_df.drop(['MarginPurchaseLimit'], axis=1)\n","  new_df = new_df.drop(['ShortSaleLimit'], axis=1)\n","  Price_df = Price_df.reset_index()\n","  Return_Test_Stock_df.reset_index()\n","  Return_Test_Stock_df = Return_Test_Stock_df[30:]\n","  # start evaluaion \n","  ###############一般回測################################\n","  y_preds_list=[]\n","  y_truth_list=[]\n","  if stock_num not in Weights_Dict.keys(): continue\n","  left_money = asset_at_the_start * Weights_Dict[stock_num] #10**6\n","  own_asset = left_money #10**6\n","  time_slide = 30 \n","  own_stock = 0 \n","  money_record = [left_money]*time_slide\n","  origin_hold_stock = 0 \n","  print(len(new_df))\n","  for i in range(time_slide, len(new_df)): \n","    tmp = new_df[i-time_slide:i]\n","    for col in new_df.columns:\n","      if col == 'Date' or col == 'y_label' or col =='bs_ratio' or col =='b_s_ratio': continue\n","      mean = statistics.mean(tmp[str(col)])\n","      stdev = statistics.stdev(tmp[str(col)])\n","      if stdev == 0: stdev = 1\n","      def test(s): \n","        return (float(s)-mean)/stdev\n","      tmp[str(col)].map(test)\n","    x = np.array(np.array(tmp).tolist()[0: time_slide]).reshape(time_slide,len(tmp.columns))\n","    predict = int(classes[np.argmax(model.predict(x.reshape(1,30,23)))])\n","    y_truth_list.append(new_df['y_label'][i])\n","    y_preds_list.append(predict)\n","    price = int(Price_df['Close'][i]*100)/100\n","    if predict == 1:\n","      if own_stock == 0:\n","        own_stock += int( left_money / ( price * (1 + 0.001425)) )\n","        left_money = left_money - own_stock*price*(1 + 0.001425)\n","    elif predict == 0 :\n","      if own_stock > 0:\n","        left_money += own_stock*price*(1 - 0.001425 - 0.003)\n","        own_stock = 0\n","    money_record.append(left_money+own_stock*price)\n","  print(str(stock_num)+\"最後資產 ：\", int(money_record[-1]),\"報酬率：\",(int(money_record[-1])-(own_asset))*100/(own_asset),\"%\")\n","  total_asset_present_value += int(money_record[-1])\n","  # insert y label and y truth\n","  Return_Test_Stock_df.insert(6, 'y_pred', y_preds_list)\n","  Return_Test_Stock_df.insert(7, 'y_true', y_truth_list)\n","  Return_Test_Stock_df.to_csv('/content/drive/My Drive/Program_Trading_Code/Return_Test_Stock_DF/Return_Test_Stock_df'+str(stock_num)+'.csv')\n","print(\"測試結束\")\n","print(\"our總投資報酬率：\", (total_asset_present_value - asset_at_the_start)*100 / asset_at_the_start, \"%\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["355\n","1102最後資產 ： 757867 報酬率： -19.724908709301086 %\n","355\n","2207最後資產 ： 13796928 報酬率： 95.23246181148458 %\n","355\n","2301最後資產 ： 1142155 報酬率： -12.105505624103605 %\n","355\n","2317最後資產 ： 1044057 報酬率： -8.06497455753726 %\n","355\n","2610最後資產 ： 1640768 報酬率： 4.104071127942479 %\n","355\n","2633最後資產 ： 4590985 報酬率： 10.12856605516171 %\n","355\n","2880最後資產 ： 504589 報酬率： -3.9778319995548026 %\n","355\n","2886最後資產 ： 1799472 報酬率： 4.854507499084951 %\n","355\n","3045最後資產 ： 203914 報酬率： -6.049385155276981 %\n","355\n","4904最後資產 ： 179010 報酬率： -15.502191699494716 %\n","355\n","5880最後資產 ： 139674 報酬率： 0.8489115692947312 %\n","測試結束\n","our總投資報酬率： 35.786415789473686 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UQxLF3dtTa-g","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604382922681,"user_tz":-480,"elapsed":1209,"user":{"displayName":"王成中","photoUrl":"","userId":"06411389530591681249"}},"outputId":"3824300a-d5c1-49a3-a7bf-35afb961ea5c"},"source":["DIC_ROR"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'1101': -19.764000000000003,\n"," '1102': -14.648900000000001,\n"," '1216': -6.0648,\n"," '1301': -7.06,\n"," '1326': -7.6747,\n"," '1402': -3.2485999999999997,\n"," '2002': -8.5951,\n"," '2105': -7.0458,\n"," '2207': -21.580299999999994,\n"," '2301': -12.4837,\n"," '2303': 14.6255,\n"," '2308': -31.8462,\n"," '2317': 37.9974,\n"," '2327': 41.98310000000001,\n"," '2330': 3.7141,\n"," '2352': 2.3966,\n"," '2357': -8.189599999999999,\n"," '2382': -0.9771000000000001,\n"," '2395': -17.3779,\n"," '2408': -20.7723,\n"," '2412': -1.8900000000000001,\n"," '2454': -38.7987,\n"," '2474': 33.9143,\n"," '2609': 1.2811000000000003,\n"," '2610': 12.2803,\n"," '2633': -28.4765,\n"," '2801': -14.8565,\n"," '2823': 0.9757000000000033,\n"," '2880': -10.6971,\n"," '2881': -3.1448,\n"," '2882': -1.6160999999999994,\n"," '2883': 3.3543000000000003,\n"," '2884': -0.8599999999999994,\n"," '2885': -20.2122,\n"," '2886': 0.26420000000000243,\n"," '2887': -5.2017,\n"," '2888': 7.102399999999999,\n"," '2890': -4.5341,\n"," '2891': -12.2232,\n"," '2892': -7.7087,\n"," '2912': -2.0581999999999994,\n"," '3008': 13.854099999999999,\n"," '3045': -5.300000000000001,\n"," '3711': -3.8466999999999985,\n"," '4904': -3.7801,\n"," '4938': 15.657599999999999,\n"," '5871': -19.3001,\n"," '5880': -10.5199,\n"," '6505': -5.647400000000001,\n"," '9904': -10.2668,\n"," '9910': -36.6685}"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"6CLsl9PDrJKs"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q6KPIdRPwofx"},"source":[""],"execution_count":null,"outputs":[]}]}