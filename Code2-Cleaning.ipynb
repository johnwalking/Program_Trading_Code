{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Code2-Cleaning.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yWdIDzwR7Qwr"},"source":["Install Ta-Lib & mpl_finance package + Mount google drive"]},{"cell_type":"code","metadata":{"id":"j7vdasm36wGF"},"source":["!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb\n","!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb\n","!dpkg -i libta.deb ta.deb\n","!pip install ta-lib\n","import talib\n","!pip install mpl_finance\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qv2uuGZI7R_K"},"source":["Import Tenserflow / Keras / Numpy / Pandas Packages"]},{"cell_type":"code","metadata":{"id":"fwY44mxV7A39"},"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import pandas_datareader as pdr\n","import seaborn as sns\n","import datetime as datetime\n","from sklearn import preprocessing\n","import requests\n","import os\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Input, Dense\n","from PIL import Image, ImageDraw, ImageFont\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n","import csv\n","import statistics\n","import math\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, SpatialDropout2D, Dropout, Flatten\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D,MaxPooling1D\n","from tensorflow.keras.layers import Activation,Dense ,Dropout ,GRU, ConvLSTM2D ,LSTM ,Bidirectional,TimeDistributed,Flatten, Conv1D, MaxPooling1D,BatchNormalization\n","from tensorflow.keras.optimizers import SGD, RMSprop\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import layers \n","from tensorflow.keras.layers import LayerNormalization\n","from tensorflow.python.keras.layers import Input, Embedding, Dot, Reshape, Dense\n","from tensorflow.python.keras.models import Model\n","from tensorflow.keras.utils import plot_model\n","from tensorflow.keras.optimizers import Adamax, Adam\n","from tensorflow.keras.layers import Input,Embedding,LSTM,Dense\n","from tensorflow.keras.models import Model\n","from tensorflow.keras import backend as K"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Re1A0wojV9Cc"},"source":["GPU Environment Setting"]},{"cell_type":"code","metadata":{"id":"BWbnpaxYWAag"},"source":["import tensorflow as tf\n","from tensorflow.keras import *\n","gpus = tf.config.list_physical_devices(\"GPU\")\n","if gpus:\n","    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n","    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n","    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n","    # tf.config.experimental.set_virtual_device_configuration(gpu0,\n","    # [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n","    tf.config.set_visible_devices([gpu0],\"GPU\") "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9vbRFwp7lfU"},"source":["Define some useful functions for exponential smoothing & one-hot encoding"]},{"cell_type":"code","metadata":{"id":"WAfwy0M57fTc"},"source":["def exponential_smoothing(days, alpha, numdata):\n","  # assign weights\n","  weights = []\n","  i = days \n","  while i>0:\n","    weights.append( math.exp(-alpha*i) )\n","    i-=1\n","  weights = np.array(weights) / sum(weights)\n","  # return data after smoothing\n","  results = []\n","  results += numdata[:days]\n","  for i in range(days, len(numdata)):\n","    results.append((np.dot( np.array(weights), np.array(numdata[i-days:i]))))\n","  return results\n","\n","classes =['0', '1']\n","def to_onelist(text):\n","    onehot = [0] * 2\n","    onehot[ int(classes.index(str(text)) ) ] = 1\n","    label_list = np.array(onehot)\n","    return label_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oN7xZMFb7wqj"},"source":["# ################################################################################\n","# stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\", \"2105\", \"2207\",# \"2227\", \n","#             \"2301\", \"2303\", \"2308\", \"2317\", \"2327\", \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\", \"2633\", \"2801\", \"2823\",\n","#             \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\", \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\", \"4904\", \"4938\", \"5871\",\n","#             \"5880\", \"6505\", \"9904\", \"9910\"]\n","\n","stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\", \"2105\", \"2207\",\n","            \"2301\", \"2303\", \"2308\", \"2317\", \"2327\", \"2330\", \"2352\", \"2357\", \"2382\",\n","            \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\", \"2801\", \"2823\",\n","            \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\", \"2886\", \"2887\", \"2888\",\n","            \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"4904\", \"4938\", \"5871\", \"5880\", \"6505\", \"9904\", \"9910\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KQ0GVm8VXr6Y"},"source":["Data Collection"]},{"cell_type":"code","metadata":{"id":"lorZ-FiYXrBC"},"source":["pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('max_colwidth',100)\n","#start = '2005/01/01'\n","start = '2012/05/02'\n","end = '2020/09/21'\n","s = start.split('/')\n","e = end.split('/')\n","start = datetime.datetime(int(s[0]), int(s[1]), int(s[2]))\n","end = datetime.datetime(int(e[0]), int(e[1]), int(e[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hGodYPqMXtS6"},"source":["# for stockno in stockNum:\n","#     # load 進 五大價格 一個量\n","#     df = pdr.DataReader(str(stockno)+'.TW', 'yahoo', start=start, end=end)\n","#     df.index = df.index.format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n","#     # print(df.columns)\n","#     stock_time = str(df.index[0]).split(\" \")[0]\n","#     #load in 融資融券\n","#     url = \"https://api.finmindtrade.com/api/v3/data\"\n","#     parameter = {\n","#         \"dataset\": \"TaiwanStockMarginPurchaseShortSale\",\n","#         \"stock_id\": str(stockno),\n","#         \"date\": stock_time,\n","#     }\n","#     data = requests.get(url, params=parameter)\n","#     data = data.json()\n","#     data = pd.DataFrame(data['data'])\n","#     #if 沒資料 則跳過這張股票\n","#     if data.empty == True:\n","#         print(str(stockno)+\" can't find data !\")\n","#         continue\n","#     ratio = []\n","#     b_total = []\n","#     s_total = []\n","#     for i in range(len(data)):\n","#         b_total.append(data['MarginPurchaseLimit'][i] - data['MarginPurchaseTodayBalance'][i])\n","#         s_total.append(data['ShortSaleLimit'][i] - data['ShortSaleTodayBalance'][i])\n","#         ratio.append(float(data['ShortSaleLimit'][i] - data['ShortSaleTodayBalance'][i])/(data['MarginPurchaseLimit'][i] - data['MarginPurchaseTodayBalance'][i]+1))\n","#     data['b_total'] = b_total\n","#     data['s_total'] = s_total\n","#     data['b_s_ratio'] = ratio\n","#     data = data.set_index('date')\n","#     #合併這兩個表格\n","#     new_df = df.join(data)\n","#     new_df = new_df.drop(['stock_id'], axis=1)\n","#     new_df = new_df.drop(['ShortSaleCashRepayment'], axis=1)\n","#     #處理三大法人投資情況 視情況加入\n","#     url = \"https://api.finmindtrade.com/api/v3/data\"\n","#     parameter = {\n","#         \"dataset\": \"InstitutionalInvestorsBuySell\",\n","#         \"stock_id\": str(stockno),\n","#         \"date\": stock_time,\n","#     }\n","#     data = requests.get(url, params=parameter)\n","#     data = data.json()\n","#     data = pd.DataFrame(data['data'])\n","#     if data.empty == True:\n","#         print(str(stockno)+\" can't find data !\")\n","#         continue\n","#     df = pd.DataFrame()\n","#     z = 0 \n","#     i = 0\n","#     while i < len(data)  :\n","#         a = data['date'][i]\n","#         count = 0\n","#         sell  = 0\n","#         buy = 0 \n","#         if i+6 < len(data)-1:\n","#             for j  in range(i, i+6):\n","#                 if data['date'][j]== a :\n","#                     count += 1\n","#                     sell += data['sell'][j]\n","#                     buy += data['buy'][j]\n","#         else:\n","#             for j in range(i, len(data)):\n","#                 if data['date'][j] == a :\n","#                     count += 1\n","#                     sell += data['sell'][j]\n","#                     buy += data['buy'][j]\n","#         df = df.append({'date': a, 'buy_volume': buy, 'sell_volume':sell, 'bs_ratio':buy/(sell+1)}, ignore_index=True)\n","#         i+=count\n","#     # combine\n","#     new_df = new_df.join(df.set_index('date'))\n","#     new_df = new_df.dropna(axis=0,how='any')\n","#     new_df.reset_index(drop=True, inplace=True)\n","#     new_df = new_df.drop(['Note'], axis=1)\n","#     for columnName in ['Close','High', 'Low','Open']:\n","#         if str(columnName) == 'y_label' : continue\n","#         new_df[str(columnName)] = exponential_smoothing(5, 0.2, list(new_df[str(columnName)]))\n","#     pred_days = 5\n","#     ans = []\n","#     for i in range(len(new_df)-pred_days):\n","#         Pi = new_df['Close'][i+pred_days]\n","#         Pj = new_df['Close'][i]\n","#         if Pi > Pj : y = 1\n","#         else: y = 0\n","#         ans.append(y)\n","#     ans += [0]*pred_days\n","#     new_df['y_label']= ans\n","    \n","#     #store file\n","#     new_df = new_df[5:]\n","#     from google.colab import files\n","#     new_df.to_csv('/content/drive/My Drive/Program_Trading_Code/0050_stock_5_5(for_price)/'+str(stockno)+'.csv')\n","#     # from google.colab import files\n","#     # files.download('/content/drive/My_Drive/Program_Trading_Code/0050_stock_5_5/'+str(stockno)+'.csv')\n","#     print(str(stockno)+\" complete....\")\n","\n","#     def normalization(df):\n","#     #{'date': a, 'buy_volume': buy, 'sell_volume':sell, 'bs_ratio':buy/(sell+1)}\n","#       dic = {}\n","#       for col in df.columns:\n","#           if col == 'Date' or col == 'y_label' or col =='bs_ratio' or col =='b_s_ratio': continue\n","#           else:\n","#               mean = statistics.mean(df[str(col)])\n","#               stdev = statistics.stdev(df[str(col)])\n","#               if stdev == 0: stdev = 1\n","#           dic[str(col)+'_mean'] = mean\n","#           dic[str(col)+'_stdev'] = stdev\n","#       return dic\n","#     record = pd.DataFrame()\n","#     days_before = 30\n","#     for i in range(days_before, len(new_df)):\n","#       record = record.append(normalization(new_df[i-days_before:i]), ignore_index=True )\n","#     record.to_csv('/content/drive/My Drive/Program_Trading_Code/0050_stock_5_5(for_price)/'+str(stockno)+'mean&stdev.csv')\n","#     print(str(stockno)+\" mean & stdev complete....\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qzXB1CVvXyDV"},"source":["################################################################################"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V-9N0pGxX46g"},"source":["Load Training / Validation / Testing Data"]},{"cell_type":"code","metadata":{"id":"Ua0EAq9kX4M1"},"source":["pd.options.mode.chained_assignment = None \n","\n","train_x = []\n","test_x = []\n","val_x = []\n","val_y = []\n","train_y = []\n","test_y = []\n","\n","for stockno in stockNum:\n","    x = []\n","    if int(stockno) == 2227: continue\n","    df = pd.read_csv('/content/drive/My Drive/Program_Trading_Code/0050_stock_5_5(for_price)/'+str(stockno)+'.csv')\n","    record = pd.read_csv('/content/drive/My Drive/Program_Trading_Code/0050_stock_5_5(for_price)/'+str(stockno)+'mean&stdev.csv')\n","    df.rename(columns={'Unnamed: 0':'Date'}, inplace=True)\n","    df = df.drop(['Date'], axis=1)\n","    df = df.drop(['MarginPurchaseLimit'], axis=1)\n","    df = df.drop(['ShortSaleLimit'], axis=1)\n","    df = df.dropna(axis=0, how='any')\n","    df.reset_index(drop=True, inplace=True)\n","    days_before = 30\n","    for i in range(days_before, len(df)):\n","        tmp = df[i-days_before:i]\n","        for col in df.columns:\n","          if col == 'Date' or col == 'y_label' or col =='bs_ratio' or col =='b_s_ratio': continue\n","          mean = record[str(col)+'_mean'][i-30]\n","          stdev = record[str(col)+'_stdev'][i-30]\n","          def test(s): \n","            return (float(s)-mean)/stdev\n","          tmp[str(col)].map(test)\n","        x.append( np.array(np.array(tmp).tolist()[0: days_before]).reshape(days_before,len(tmp.columns)))\n","    y = list(df['y_label'][days_before:]) \n","    #train:val:test = 8:1:1\n","    tr_va = int(len(x)*8/10)\n","    va_te = int(len(x)*9/10)\n","    # print(\"no: \", tr_va, \"no: \", va_te, \"leng: \", len(y))\n","    train_x = train_x + x[:tr_va]\n","    train_y = train_y + y[:tr_va]\n","    val_x = val_x + x[tr_va: va_te]\n","    val_y = val_y + y[tr_va: va_te]\n","    test_x = test_x + x[va_te:]\n","    test_y = test_y +y[va_te:]\n","    print(str(stockno)+\" loaded....\")\n","    # print(len(train_x), len(val_x), len(test_x))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aAvyCvdAYN2o"},"source":["Convert raw data label to one-hot encoding"]},{"cell_type":"code","metadata":{"id":"K82RZ0W8YAIU"},"source":["y = [] \n","for i in range(len(train_y)):\n","    y.append(to_onelist(str(train_y[i])))\n","train_y = y\n","\n","y = [] \n","for i in range(len(test_y)):\n","    y.append(to_onelist(str(test_y[i])))\n","test_y = y\n","\n","y = [] \n","for i in range(len(val_y)):\n","    y.append(to_onelist(str(val_y[i])))\n","val_y = y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PU3bqxIgYW5m"},"source":["train_x = np.array(train_x).reshape(len(train_x), 30, 23)\n","test_x  = np.array(test_x).reshape(len(test_x), 30, 23)\n","val_x   = np.array(val_x).reshape(len(val_x), 30, 23)\n","train_y = np.array(train_y).reshape(len(train_y),2)\n","test_y  = np.array(test_y).reshape(len(test_y),2)\n","val_y   = np.array(val_y).reshape(len(val_y),2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z9OsQJq0YaXJ"},"source":["def count_label_dist(arr):\n","    count_1 = 0 \n","    count_0 = 0 \n","    for i in range(len(arr)):\n","        if list(arr[i])== list([0,1]): count_1 += 1\n","        elif list(arr[i])== list([1,0]): count_0 += 1\n","    print(count_0, count_1)\n","    return count_0, count_1\n","\n","c_0, c_1 = count_label_dist(train_y)\n","c_0, c_1 = count_label_dist(val_y)\n","c_0, c_1 = count_label_dist(test_y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1CxNgjjfYeFc"},"source":["Define LSTM Model"]},{"cell_type":"code","metadata":{"id":"pcClSoFpYgH6"},"source":["def lstm4_model(input_shape , n_classes):\n","    model = Sequential()\n","    model.add(BatchNormalization(input_shape=(input_shape[0],input_shape[1])))\n","    model.add(LSTM(25,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(12,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(6,return_sequences=True))\n","    model.add(BatchNormalization())\n","    model.add(LSTM(3,return_sequences=True))\n","    model.add(Flatten())\n","    model.add(BatchNormalization())\n","    model.add(Dense(90, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(25, activation='relu', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    model.add(BatchNormalization())\n","    model.add(Dense(2, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(l=0.001)))\n","    lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-4, decay_steps=100000, decay_rate=0.9)\n","    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=lr_schedule), metrics=['accuracy'])\n","    model.summary()\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wOsXWuDpYkSi"},"source":["Prepare For Training"]},{"cell_type":"code","metadata":{"id":"TQaB38zHYgw_"},"source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n","# tf.keras.backend.clear_session()\n","model = lstm4_model((30, 23), 2)\n","callback = EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1, mode=\"auto\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AfttHDdwYqpy"},"source":["# start training\n","history = model.fit(train_x, train_y , epochs=150, batch_size= 256, validation_data=(val_x, val_y), callbacks=[callback, tensorboard_callback] )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"huHjs-cDY4Wa"},"source":["# save model\n","model.save('/content/drive/My Drive/Program_Trading_Code/lstm4_xxx.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zsvgqmbHYu66"},"source":["# evaluate testing\n","prediction_y = []\n","truth_y = []\n","for i in range(len(test_y)):\n","  prediction_y.append(int(classes[np.argmax(model.predict(test_x[i].reshape(1,30,23)))]))\n","  truth_y.append(int(classes[np.argmax(test_y[i])]))\n","print(\"Accuracy: \")\n","print( 1 - (np.sum(np.logical_xor(np.array(prediction_y), np.array(truth_y))))/len(test_y) )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XVcoawlrZQ48"},"source":["Validation Rate of Return"]},{"cell_type":"code","metadata":{"id":"--zg5ITIZQcd"},"source":["#選定欲回測的model\n","from keras.models import load_model\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('max_colwidth',100)\n","model = load_model('/content/drive/My Drive/Program_Trading_Code/lstm4_5_5.h5')\n","stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\", \"2105\", \"2207\", #\"2227\", \n","            \"2301\", \"2303\", \"2308\", \"2317\", \"2327\", \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\", \"2633\", \"2801\", \"2823\",\n","            \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\", \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\", \"4904\", \"4938\", \"5871\",\n","            \"5880\", \"6505\", \"9904\", \"9910\"]\n","#Set the information of data\n","start = '2018/08/01'\n","end = '2019/06/03'\n","#start = '2019/06/04'\n","#end = '2020/11/11'\n","s = start.split('/')\n","e = end.split('/')\n","start = datetime.datetime(int(s[0]), int(s[1]), int(s[2]))\n","end = datetime.datetime(int(e[0]), int(e[1]), int(e[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9UOw2MtZXPW"},"source":["asset_at_the_start = 51 * 10**6\n","total_asset_present_value = 0\n","ROR_Validation = {}\n","for stock_num in stockNum:\n","  Price_df = pdr.DataReader(str(stock_num)+'.TW', 'yahoo', start=start, end=end)\n","  Return_Test_Stock_df = Price_df.copy(deep=True)\n","  Price_df.index = Price_df.index.format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n","  stock_time = str(Price_df.index[0]).split(\" \")[0]\n","  url = \"https://api.finmindtrade.com/api/v3/data\" #load in 融資融券\n","  parameter = {\n","    \"dataset\": \"TaiwanStockMarginPurchaseShortSale\",\n","    \"stock_id\": str(stock_num),\n","    \"date\": stock_time,\n","  }\n","  data = requests.get(url, params=parameter)\n","  data = data.json()\n","  data = pd.DataFrame(data['data'])\n","  data['b_total'] = data['MarginPurchaseLimit'] - data['MarginPurchaseTodayBalance']\n","  data['s_total'] = data['ShortSaleLimit'] - data['ShortSaleTodayBalance']\n","  data['b_s_ratio'] = (data['ShortSaleLimit'] - data['ShortSaleTodayBalance'])/(data['MarginPurchaseLimit'] - data['MarginPurchaseTodayBalance']+1)\n","  data = data.set_index('date')\n","  # 合併這兩個表格\n","  new_df = Price_df.join(data)\n","  new_df = new_df.drop(['stock_id'], axis=1)\n","  new_df = new_df.drop(['ShortSaleCashRepayment'], axis=1)\n","  url = \"https://api.finmindtrade.com/api/v3/data\" #load in三大法人投資情況\n","  parameter = {\n","    \"dataset\": \"InstitutionalInvestorsBuySell\",\n","    \"stock_id\": str(stock_num),\n","    \"date\": stock_time,\n","  }\n","  data = requests.get(url, params=parameter)\n","  data = data.json()\n","  data = pd.DataFrame(data['data'])\n","  df = pd.DataFrame()\n","  z = 0 \n","  i = 0\n","  while i < len(data)  :\n","    a = data['date'][i]\n","    count = 0\n","    sell = 0\n","    buy = 0 \n","    if i+6 < len(data)-1:\n","        for j  in range(i, i+6):\n","            if data['date'][j]== a :\n","              count += 1\n","              sell += data['sell'][j]\n","              buy += data['buy'][j]\n","    else:\n","      for j in range(i, len(data)):\n","        if data['date'][j] == a :\n","          count += 1\n","          sell += data['sell'][j]\n","          buy += data['buy'][j]\n","    df = df.append({'date': a, 'buy_volume': buy, 'sell_volume':sell, 'bs_ratio':buy/(sell+1)}, ignore_index=True)\n","    i+=count\n","  new_df = new_df.join(df.set_index('date'))\n","  new_df = new_df.fillna(axis=0,method='ffill')\n","  new_df = new_df.drop(['Note'], axis=1)\n","  new_df.reset_index(drop=True, inplace=True)\n","  for columnName in new_df.columns:\n","    if str(columnName) == 'y_label' or str(columnName) == 'index': continue\n","    new_df[str(columnName)] = exponential_smoothing(5, 0.2, list(new_df[str(columnName)]))\n","    days = 10\n","    ans = [0]*days\n","    for i in range(days,len(new_df)):\n","      Pi = new_df['Close'][i]\n","      Pj = new_df['Close'][i-days]\n","      if Pi > Pj : y = 1\n","      else: y = 0\n","      ans.append(y)\n","  new_df['y_label']= ans\n","  new_df = new_df.reset_index()\n","  new_df.rename(columns={'index':'Date'}, inplace=True)\n","  time_list = list(new_df['Date'])\n","  new_df = new_df.drop(['Date'], axis=1)\n","  new_df = new_df.drop(['MarginPurchaseLimit'], axis=1)\n","  new_df = new_df.drop(['ShortSaleLimit'], axis=1)\n","  Price_df = Price_df.reset_index()\n","  Return_Test_Stock_df.reset_index()\n","  Return_Test_Stock_df = Return_Test_Stock_df[30:]\n","  # start evaluaion \n","  ###############一般回測################################\n","  y_preds_list=[]\n","  y_truth_list=[]\n","  left_money = asset_at_the_start*(1/51)\n","  own_asset = left_money \n","  time_slide = 30 \n","  own_stock = 0 \n","  money_record = [left_money]*time_slide\n","  origin_hold_stock = 0 \n","  #print(len(new_df))\n","  for i in range(time_slide, len(new_df)): \n","    tmp = new_df[i-time_slide:i]\n","    for col in new_df.columns:\n","      if col == 'Date' or col == 'y_label' or col =='bs_ratio' or col =='b_s_ratio': continue\n","      mean = statistics.mean(tmp[str(col)])\n","      stdev = statistics.stdev(tmp[str(col)])\n","      if stdev == 0: stdev = 1\n","      def test(s): \n","        return (float(s)-mean)/stdev\n","      tmp[str(col)].map(test)\n","    x = np.array(np.array(tmp).tolist()[0: time_slide]).reshape(time_slide,len(tmp.columns))\n","    predict = int(classes[np.argmax(model.predict(x.reshape(1,30,23)))])\n","    y_truth_list.append(new_df['y_label'][i])\n","    y_preds_list.append(predict)\n","    price = int(Price_df['Close'][i]*100)/100\n","    if predict == 1:\n","      if own_stock == 0:\n","        own_stock += int( left_money / ( price * (1 + 0.001425)) )\n","        left_money = left_money - own_stock*price*(1 + 0.001425)\n","    elif predict == 0 :\n","      if own_stock > 0:\n","        left_money += own_stock*price*(1 - 0.001425 - 0.003)\n","        own_stock = 0\n","    money_record.append(left_money+own_stock*price)\n","  print(str(stock_num)+\"最後資產 ：\", int(money_record[-1]),\"報酬率：\",(int(money_record[-1])-(own_asset))*100/(own_asset),\"%\")\n","  total_asset_present_value += int(money_record[-1])\n","  ROR_Validation[stock_num] = ((int(money_record[-1])-(own_asset))*100/(own_asset))/100\n","  print(stock_num)\n","  print(ROR_Validation[stock_num])\n","print(\"測試結束\")\n","print(\"our總投資報酬率：\", (total_asset_present_value - asset_at_the_start)*100 / asset_at_the_start, \"%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yEtYjaCDZx50"},"source":["###\n","# lstm4_5_5 validation ror -> \n","DIC_ROR = {'1101': -8.6096, '1102': 10.1097, '1216': -0.7935, '1301': -9.4354, '1326': -17.9471, '1402': -11.2923, '2002': -9.5477, '2105': -22.0487, '2207': 75.6757, '2301': 13.9152, '2303': -1.3974, '2308': -4.2712, '2317': 12.161, '2327': -8.3967, '2330': -7.3642, '2352': -0.7237, '2357': -24.599, '2382': 13.4822, '2395': 4.3062, '2408': -15.2948, '2412': 0.2369, '2454': -12.0878, '2474': -10.7817, '2609': -5.6983, '2610': 16.8774, '2633': 44.6408, '2801': -4.7183, '2823': -16.7678, '2880': 5.6272, '2881': -15.3308, '2882': -20.0186, '2883': -11.0375, '2884': 21.6132, '2885': -4.1252, '2886': 18.3774, '2887': -6.0796, '2888': -17.4904, '2890': 6.5775, '2891': -14.73, '2892': 2.4412, '2912': -16.2974, '3008': 0.411, '3045': 2.3242, '3711': -20.7536, '4904': 2.2686, '4938': -0.4619, '5871': -1.0963, '5880': 1.4831, '6505': -15.977, '9904': 4.9289, '9910': -14.1742}\n","# ROR_Validation = {'1101': -0.086096, '1102': 0.101097, '1216': -0.007935, '1301': -0.094354, '1326': -0.179471, '1402': -0.112923, '2002': -0.095477, '2105': -0.220487, '2207': 0.756757,\n","#  '2301': 0.139152, '2303': -0.013974, '2308': -0.042712, '2317': 0.12161, '2327': -0.08396699999999999, '2330': -0.073642, '2352': -0.007237, '2357': -0.24599000000000001, '2382': 0.134822,\n","#  '2395': 0.043061999999999996, '2408': -0.152948, '2412': 0.002369, '2454': -0.120878, '2474': -0.10781700000000001, '2609': -0.056983, '2610': 0.168774, '2633': 0.44640799999999997,\n","#  '2801': -0.047183, '2823': -0.16819299999999998, '2880': 0.056272, '2881': -0.153308, '2882': -0.200186, '2883': -0.110375, '2884': 0.216132, '2885': -0.041252000000000004, '2886': 0.18377400000000002,\n","#  '2887': -0.060796, '2888': -0.174904, '2890': 0.065775, '2891': -0.14730000000000001, '2892': 0.024412, '2912': -0.162974, '3008': 0.00411, '3045': 0.023242, '3711': -0.207536,\n","#  '4904': 0.022686, '4938': -0.004619, '5871': -0.010963, '5880': 0.014831, '6505': -0.15977, '9904': 0.049289, '9910': -0.141742}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8eGFIYjeQdfs"},"source":["# validation ROR to csv\n","DIC_ROR = {'1101': -8.6096, '1102': 10.1097, '1216': -0.7935, '1301': -9.4354, '1326': -17.9471, '1402': -11.2923, '2002': -9.5477, '2105': -22.0487, '2207': 75.6757, '2301': 13.9152, '2303': -1.3974, '2308': -4.2712, '2317': 12.161, '2327': -8.3967, '2330': -7.3642, '2352': -0.7237, '2357': -24.599, '2382': 13.4822, '2395': 4.3062, '2408': -15.2948, '2412': 0.2369, '2454': -12.0878, '2474': -10.7817, '2609': -5.6983, '2610': 16.8774, '2633': 44.6408, '2801': -4.7183, '2823': -16.7678, '2880': 5.6272, '2881': -15.3308, '2882': -20.0186, '2883': -11.0375, '2884': 21.6132, '2885': -4.1252, '2886': 18.3774, '2887': -6.0796, '2888': -17.4904, '2890': 6.5775, '2891': -14.73, '2892': 2.4412, '2912': -16.2974, '3008': 0.411, '3045': 2.3242, '3711': -20.7536, '4904': 2.2686, '4938': -0.4619, '5871': -1.0963, '5880': 1.4831, '6505': -15.977, '9904': 4.9289, '9910': -14.1742}\n","Validation_ROR_df = pd.DataFrame(columns =['Name', 'weights'])\n","for key in DIC_ROR:\n","  Validation_ROR_df = Validation_ROR_df.append({'Name': key, 'weights': DIC_ROR[key]}, ignore_index=True)\n","Validation_ROR_df.to_csv('/content/drive/My Drive/Program_Trading_Code/Validation_ROR_df.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wvtPFwJCaAve"},"source":["Convert Rate of Return to Weights"]},{"cell_type":"code","metadata":{"id":"1XH4O_XiaDN9"},"source":["Weights_Dict = {}\n","for key in DIC_ROR:\n","  # print(key, '->', DIC_ROR[key])\n","  if DIC_ROR[key] > 0:\n","    Weights_Dict[key] = DIC_ROR[key]\n","WeightSum = sum(Weights_Dict.values())\n","NewWeightSum = 0\n","for key in Weights_Dict:\n","  Weights_Dict[key] /= WeightSum\n","  print(key, '->', Weights_Dict[key])\n","  NewWeightSum += Weights_Dict[key]\n","print(Weights_Dict)\n","print(NewWeightSum)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8x1apl-acdD"},"source":["###\n","# lstm 4_5_5 Weights for testing ->\n","Weights_Dict = {'1102': 0.0392674671615576, '2207': 0.2939348412591753, '2301': 0.054048553275221456, '2317': 0.0472349988774842, '2382': 0.05236672164016261, '2395': 0.016725873872726126, '2412': 0.0009201522271257303, '2610': 0.06555414604513213, '2633': 0.17339101536797932, '2880': 0.021856819807859477, '2884': 0.08394864548465104, '2886': 0.0713803526330958, '2890': 0.02554791588822073, '2892': 0.009481957015024621, '3008': 0.0015963806051020478, '3045': 0.009027512901163454, '4904': 0.008811554843636268, '5880': 0.005760564660405955, '9904': 0.019144526434276114}\n","0.9999999999999999"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nm9pTck4avIx"},"source":["Save the weights for testing to csv file"]},{"cell_type":"code","metadata":{"id":"gvlP5XrgaK3L"},"source":["Weights_Dict = {'1102': 0.0392674671615576, '2207': 0.2939348412591753, '2301': 0.054048553275221456, '2317': 0.0472349988774842, '2382': 0.05236672164016261, '2395': 0.016725873872726126, '2412': 0.0009201522271257303, '2610': 0.06555414604513213, '2633': 0.17339101536797932, '2880': 0.021856819807859477, '2884': 0.08394864548465104, '2886': 0.0713803526330958, '2890': 0.02554791588822073, '2892': 0.009481957015024621, '3008': 0.0015963806051020478, '3045': 0.009027512901163454, '4904': 0.008811554843636268, '5880': 0.005760564660405955, '9904': 0.019144526434276114}\n","stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\", \"2105\", \"2207\",# \"2227\", \n","            \"2301\", \"2303\", \"2308\", \"2317\", \"2327\", \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\", \"2633\", \"2801\", \"2823\",\n","            \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\", \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\", \"4904\", \"4938\", \"5871\",\n","            \"5880\", \"6505\", \"9904\", \"9910\"]\n","Return_Dict = {}\n","for key in stockNum:\n","  if key not in Weights_Dict.keys(): Return_Dict[key] = 0.0\n","  else: Return_Dict[key] = Weights_Dict[key]\n","Return_Weight_df = pd.DataFrame(columns =['Name', 'weights'])\n","for key in Return_Dict:\n","  Return_Weight_df = Return_Weight_df.append({'Name': key, 'weights': Return_Dict[key]}, ignore_index=True)\n","Return_Weight_df.to_csv('/content/drive/My Drive/Program_Trading_Code/Return_Weight_df.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0oRSp1zJa47D"},"source":["Find the Rate of Return in Testing"]},{"cell_type":"code","metadata":{"id":"MY64Gxeda9nB"},"source":["#選定欲回測的model\n","from keras.models import load_model\n","pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('max_colwidth',100)\n","model = load_model('/content/drive/My Drive/Program_Trading_Code/lstm4_5_5.h5')\n","stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\", \"2105\", \"2207\", #\"2227\", \n","            \"2301\", \"2303\", \"2308\", \"2317\", \"2327\", \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\", \"2633\", \"2801\", \"2823\",\n","            \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\", \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\", \"4904\", \"4938\", \"5871\",\n","            \"5880\", \"6505\", \"9904\", \"9910\"]\n","start = '2019/06/25'\n","end = '2020/09/21'\n","s = start.split('/')\n","e = end.split('/')\n","start = datetime.datetime(int(s[0]), int(s[1]), int(s[2]))\n","end = datetime.datetime(int(e[0]), int(e[1]), int(e[2]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B36z9UF-DJGe"},"source":["Weights_Dict = {'1102': 0.0392674671615576, '2207': 0.2939348412591753, '2301': 0.054048553275221456, '2317': 0.0472349988774842, '2382': 0.05236672164016261, '2395': 0.016725873872726126, '2412': 0.0009201522271257303, '2610': 0.06555414604513213, '2633': 0.17339101536797932, '2880': 0.021856819807859477, '2884': 0.08394864548465104, '2886': 0.0713803526330958, '2890': 0.02554791588822073, '2892': 0.009481957015024621, '3008': 0.0015963806051020478, '3045': 0.009027512901163454, '4904': 0.008811554843636268, '5880': 0.005760564660405955, '9904': 0.019144526434276114}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QpUf1pKYbL8H"},"source":["asset_at_the_start = 19 * 10**6\n","total_asset_present_value = 0\n","ROR_Test = {}\n","\n","time_point_asset = [0]*276\n","for stock_num in stockNum:\n","  if stock_num not in Weights_Dict.keys(): continue\n","  #先算出之後回測用的價位\n","  Price_df = pdr.DataReader(str(stock_num)+'.TW', 'yahoo', start=start, end=end)\n","  Return_Test_Stock_df = Price_df.copy(deep=True)\n","  Price_df.index = Price_df.index.format(formatter=lambda x: x.strftime('%Y-%m-%d'))\n","  stock_time = str(Price_df.index[0]).split(\" \")[0]\n","  url = \"https://api.finmindtrade.com/api/v3/data\" #load in 融資融券\n","  parameter = {\n","    \"dataset\": \"TaiwanStockMarginPurchaseShortSale\",\n","    \"stock_id\": str(stock_num),\n","    \"date\": stock_time,\n","  }\n","  data = requests.get(url, params=parameter)\n","  data = data.json()\n","  data = pd.DataFrame(data['data'])\n","  data['b_total'] = data['MarginPurchaseLimit'] - data['MarginPurchaseTodayBalance']\n","  data['s_total'] = data['ShortSaleLimit'] - data['ShortSaleTodayBalance']\n","  data['b_s_ratio'] = (data['ShortSaleLimit'] - data['ShortSaleTodayBalance'])/(data['MarginPurchaseLimit'] - data['MarginPurchaseTodayBalance']+1)\n","  data = data.set_index('date')\n","  # 合併這兩個表格\n","  new_df = Price_df.join(data)\n","  new_df = new_df.drop(['stock_id'], axis=1)\n","  new_df = new_df.drop(['ShortSaleCashRepayment'], axis=1)\n","  url = \"https://api.finmindtrade.com/api/v3/data\" #load in三大法人投資情況\n","  parameter = {\n","    \"dataset\": \"InstitutionalInvestorsBuySell\",\n","    \"stock_id\": str(stock_num),\n","    \"date\": stock_time,\n","  }\n","  data = requests.get(url, params=parameter)\n","  data = data.json()\n","  data = pd.DataFrame(data['data'])\n","  df = pd.DataFrame()\n","  z = 0 \n","  i = 0\n","  while i < len(data)  :\n","    a = data['date'][i]\n","    count = 0\n","    sell = 0\n","    buy = 0 \n","    if i+6 < len(data)-1:\n","        for j  in range(i, i+6):\n","            if data['date'][j]== a :\n","              count += 1\n","              sell += data['sell'][j]\n","              buy += data['buy'][j]\n","    else:\n","      for j in range(i, len(data)):\n","        if data['date'][j] == a :\n","          count += 1\n","          sell += data['sell'][j]\n","          buy += data['buy'][j]\n","    df = df.append({'date': a, 'buy_volume': buy, 'sell_volume':sell, 'bs_ratio':buy/(sell+1)}, ignore_index=True)\n","    i+=count\n","  new_df = new_df.join(df.set_index('date'))\n","  new_df = new_df.fillna(axis=0,method='ffill')\n","  new_df = new_df.drop(['Note'], axis=1)\n","  new_df.reset_index(drop=True, inplace=True)\n","  for columnName in new_df.columns:\n","    if str(columnName) == 'y_label' or str(columnName) == 'index': continue\n","    new_df[str(columnName)] = exponential_smoothing(5, 0.2, list(new_df[str(columnName)]))\n","    days = 10\n","    ans = [0]*days\n","    for i in range(days,len(new_df)):\n","      Pi = new_df['Close'][i]\n","      Pj = new_df['Close'][i-days]\n","      if Pi > Pj : y = 1\n","      else: y = 0\n","      ans.append(y)\n","  new_df['y_label']= ans\n","  new_df = new_df.reset_index()\n","  new_df.rename(columns={'index':'Date'}, inplace=True)\n","  time_list = list(new_df['Date'])\n","  new_df = new_df.drop(['Date'], axis=1)\n","  new_df = new_df.drop(['MarginPurchaseLimit'], axis=1)\n","  new_df = new_df.drop(['ShortSaleLimit'], axis=1)\n","  Price_df = Price_df.reset_index()\n","  Return_Test_Stock_df.reset_index()\n","  Return_Test_Stock_df = Return_Test_Stock_df[30:]\n","  # start evaluaion \n","  ###############一般回測################################\n","  y_preds_list=[]\n","  y_truth_list=[]\n","  if stock_num not in Weights_Dict.keys(): continue\n","  left_money = asset_at_the_start * Weights_Dict[stock_num] #10**6\n","  own_asset = left_money #10**6\n","  time_slide = 30 \n","  own_stock = 0 \n","  money_record = [left_money]*time_slide\n","  origin_hold_stock = 0 \n","  print(len(new_df))\n","  for i in range(time_slide, len(new_df)): \n","    # print(\"長度\", len(new_df)-time_slide)\n","    tmp = new_df[i-time_slide:i]\n","    for col in new_df.columns:\n","      if col == 'Date' or col == 'y_label' or col =='bs_ratio' or col =='b_s_ratio': continue\n","      mean = statistics.mean(tmp[str(col)])\n","      stdev = statistics.stdev(tmp[str(col)])\n","      if stdev == 0: stdev = 1\n","      def test(s): \n","        return (float(s)-mean)/stdev\n","      tmp[str(col)].map(test)\n","    x = np.array(np.array(tmp).tolist()[0: time_slide]).reshape(time_slide,len(tmp.columns))\n","    predict = int(classes[np.argmax(model.predict(x.reshape(1,30,23)))])\n","    y_truth_list.append(new_df['y_label'][i])\n","    y_preds_list.append(predict)\n","    price = int(Price_df['Close'][i]*100)/100\n","    if predict == 1:\n","      if own_stock == 0:\n","        own_stock += int( left_money / ( price * (1 + 0.001425)) )\n","        left_money = left_money - own_stock*price*(1 + 0.001425)\n","    elif predict == 0 :\n","      if own_stock > 0:\n","        left_money += own_stock*price*(1 - 0.001425 - 0.003)\n","        own_stock = 0\n","    money_record.append(left_money+own_stock*price)\n","    time_point_asset[i-30]+=left_money+own_stock*price\n","  print(str(stock_num)+\"最後資產 ：\", int(money_record[-1]),\"報酬率：\",(int(money_record[-1])-(own_asset))*100/(own_asset),\"%\")\n","  total_asset_present_value += int(money_record[-1])\n","  # insert y label and y truth\n","  #Return_Test_Stock_df.insert(6, 'y_pred', y_preds_list)\n","  #Return_Test_Stock_df.insert(7, 'y_true', y_truth_list)\n","  #Return_Test_Stock_df.to_csv('/content/drive/My Drive/Program_Trading_Code/Return_Test_Stock_DF/Return_Test_Stock_df'+str(stock_num)+'.csv')\n","  ROR_Test[stock_num] = ((int(money_record[-1])-(own_asset))*100/(own_asset))/100\n","  print(stock_num)\n","  print(ROR_Test[stock_num])\n","print(\"測試結束\")\n","print(\"our總投資報酬率：\", (total_asset_present_value - asset_at_the_start)*100 / asset_at_the_start, \"%\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HY71AuxUFhXk"},"source":["total_df = pd.DataFrame(columns =['date','profit_rate'])\n","\n","df  = pd.read_csv('/content/drive/My Drive/Program_Trading_Code/Return_Test_Stock_DF/Return_Test_Stock_df'+str(2395)+'.csv')\n","date = list(df['Date'])\n","# time_point_asset = [19*1000000]*30 + time_point_asset\n","\n","print(len(time_point_asset), len(date))\n","\n","for i in range(len(date)):\n","  print(time_point_asset[i]/19*1000000)\n","  total_df = total_df.append({'date': date[i], 'profit_rate': (time_point_asset[i]-19*1000000)*100/(19*1000000) }, ignore_index=True)\n","total_df.to_csv('/content/drive/My Drive/Program_Trading_Code/total19.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"orJjCB_WFJsY"},"source":["Weights_Dict = {'1102': 0.0392674671615576, '2207': 0.2939348412591753, '2301': 0.054048553275221456, '2317': 0.0472349988774842, '2382': 0.05236672164016261, '2395': 0.016725873872726126, '2412': 0.0009201522271257303, '2610': 0.06555414604513213, '2633': 0.17339101536797932, '2880': 0.021856819807859477, '2884': 0.08394864548465104, '2886': 0.0713803526330958, '2890': 0.02554791588822073, '2892': 0.009481957015024621, '3008': 0.0015963806051020478, '3045': 0.009027512901163454, '4904': 0.008811554843636268, '5880': 0.005760564660405955, '9904': 0.019144526434276114}\n","stockNum = [\"1101\", \"1102\", \"1216\", \"1301\", \"1326\", \"1402\", \"2002\", \"2105\", \"2207\",# \"2227\", \n","            \"2301\", \"2303\", \"2308\", \"2317\", \"2327\", \"2330\", \"2352\", \"2357\", \"2382\", \"2395\", \"2408\", \"2412\", \"2454\", \"2474\", \"2609\", \"2610\", \"2633\", \"2801\", \"2823\",\n","            \"2880\", \"2881\", \"2882\", \"2883\", \"2884\", \"2885\", \"2886\", \"2887\", \"2888\", \"2890\", \"2891\", \"2892\", \"2912\", \"3008\", \"3045\", \"3711\", \"4904\", \"4938\", \"5871\",\n","            \"5880\", \"6505\", \"9904\", \"9910\"]\n","Return_Dict = {}\n","for key in stockNum:\n","  if key not in Weights_Dict.keys(): Return_Dict[key] = 0.0\n","  else: Return_Dict[key] = Weights_Dict[key]\n","Return_Weight_df = pd.DataFrame(columns =['Name', 'weights', 'Test_ROR'])\n","for key in Return_Dict:\n","  if key not in ROR_Test.keys(): Return_Weight_df = Return_Weight_df.append({'Name': key, 'weights': Return_Dict[key], 'Test_ROR': 0.0}, ignore_index=True)\n","  else: Return_Weight_df = Return_Weight_df.append({'Name': key, 'weights': Return_Dict[key], 'Test_ROR': ROR_Test[key]}, ignore_index=True)\n","Return_Weight_df.to_csv('/content/drive/My Drive/Program_Trading_Code/Return_Weight_df.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wJhX9YwXL5b5"},"source":["predict = 5\n","predict = 1 if predict >= 3 else 0\n","print(predict)\n","\n","addition_money = 5\n","addition_money = 0 if addition_money < 0 else addition_money\n","print(addition_money)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HsIWaTQOOqKn"},"source":[""],"execution_count":null,"outputs":[]}]}